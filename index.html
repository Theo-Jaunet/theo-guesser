<!DOCTYPE html>
<html lang="en">
<head>

    <!-- Basic Page Needs
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <meta charset="utf-8">
    <title>Projection</title>
    <meta name="description" content="">
    <meta name="author" content="Theo Jaunet, Romain Vuillemot, and Christian Wolf">
    <script src="https://d3js.org/d3.v5.min.js"></script>
    <!-- Mobile Specific Metas
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- FONT
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

    <!-- CSS
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link rel="stylesheet" href="assets/css/normalize.css">
    <link rel="stylesheet" href="assets/css/skeleton.css">

    <!-- Favicon
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link rel="icon" type="image/png" href="assets/images/favicon/favicon.ico">
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"
            integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
    <script src="assets/js/projector.js"></script>
    <script src="assets/js/local.js"></script>
    <style>
        path {

            /*opacity: 0.8;*/
        }

        .play {
            border: none;
        }

        .play:hover {

            cursor: pointer;
            transform: scale(1.1);
        }


        input::-moz-focus-inner {
            border: 0;
        }

        input[type=range]::-moz-focus-outer {
            border: 0;
        }

        input[type="range"] {
            -webkit-appearance: none;
            -moz-apperance: none;
            border-radius: 6px;
            height: 6px;
            user-select: none;
            outline: none;
            width: 100%;
            border: 0;
            background-image: -webkit-gradient(
                    linear,
                    left top,
                    right top,
                    color-stop(0, #233E34),
                    color-stop(0, #C5C5C5)
            );
            -webkit-touch-callout: none; /* iOS Safari */
            -webkit-user-select: none; /* Safari */
            -khtml-user-select: none; /* Konqueror HTML */
            -moz-user-select: none; /* Firefox */
            -ms-user-select: none; /* Internet Explorer/Edge */
            user-select: none;
            user-focus: none;
            /* Non-prefixed version, currently
                                             supported by Chrome and Opera */
        }

        input[type='range']::-webkit-slider-thumb {
            -webkit-appearance: none !important;
            background-color: #183d4e;
            border: 1px solid #183d4e;
            height: 20px;
            width: 20px;
            border-radius: 50%;
            -webkit-touch-callout: none; /* iOS Safari */
            -webkit-user-select: none; /* Safari */
            -khtml-user-select: none; /* Konqueror HTML */
            -moz-user-select: none; /* Firefox */
            -ms-user-select: none; /* Internet Explorer/Edge */
            user-select: none;
            cursor: pointer;
        }

        input[type='range']::-moz-range-thumb {
            -webkit-appearance: none !important;
            background-color: #183d4e;
            border: 1px solid #183d4e;
            height: 18px;
            width: 18px;
            opacity: 1;
            border-radius: 50%;
            -webkit-touch-callout: none; /* iOS Safari */
            -webkit-user-select: none; /* Safari */
            -khtml-user-select: none; /* Konqueror HTML */
            -moz-user-select: none; /* Firefox */
            -ms-user-select: none; /* Internet Explorer/Edge */
            user-select: none;
            cursor: pointer;
        }

        img {

            border: #888888 solid 1px;
            margin: 2px;
        }
    </style>

</head>
<body>

<!-- Primary Page Layout
–––––––––––––––––––––––––––––––––––––––––––––––––– -->
<div class="container" style="margin-bottom: 5%; width: 1100px;max-width: 1100px">
    <div class="row">
        <div class="twelve column" style="margin-top: 10%">
            <h4 style="text-align: center"><span style="text-decoration:line-through rgba(0,0,0,0.4) ">Geo</span> Theo
                Guesser </h4>
            <h5 style="font-size: 2.2rem;color: rgba(0,0,0,0.5);text-align: center">
                If you wake up in Theo’s appartment could you guess where you are?
            </h5>
        </div>
    </div>


    <div>

    </div>

    <div class="row">
        <div class="twelve column" style="margin-top: 10%">
            <h4 style="text-align: left"> Introduction </h4>
            <p>
                The last years have witnessed the soaring of Machine Learning, which has provided disruptive performance
                gains in several fields. Apart from undeniable advances in methodology, these gains are often attributed
                to massive amounts of training data and computing power, which led to breakthroughs in speech
                recognition, computer vision and language processing. Extending these advances to robotics, planning and
                control has proven to be difficult, as these applications often require learning from interactions
                instead of static data. They also currently suffer from low sample efficiency, often requiring billions
                of interactions <a href="#ref1">[1]</a>, which makes learning in real-time from physical interactions
                with real robots
                intractable.
                <br/><br/>
                Simulation is a promising direction, which allows training to proceed significantly faster than physical
                time on fast modern hardware, easily distributing multiple simulated environments over a large number of
                cores and machines. However, neural networks trained in simulated environments generally perform poorly
                when deployed on real robots and environments, mainly to the “sim2real” gap, i.e. the lack of accuracy
                in simulating real environment conditions [X][X][X]. The exact nature of the gap is often difficult to
                pinpoint, and modelling this gap and a successful transfer from simulation to physical environments has
                become a major subfield between machine learning and robotics.
                <br/><br/>
                This work is at the crossroads of three different fields and explores techniques of data visualization
                to advance machine learning for robotics applications. We propose new techniques for the visualization
                of the sim2real gap, which provide insights into the difference in performance obtained when neural
                networks are applied out of distribution (OOD) in real settings. The objective is to pinpoint transfer
                problems and to assist researchers and engineers in the fields of machine learning for robotics to
                design neural models which better transfer to real world scenarios.
                <br/><br/>
                The concrete application we target is robot localization, also called ego-pose estimation, which
                requires to estimate the 3D position and viewpoint (2 angles) of a mobile robot navigating in a 3D
                environment, in our case an apartment. At each time step t, the robot
                observes two ego-centric images (an RGB image It and a depth image Dt) from an onboard camera, from
                which a convolutional neural network directly regresses the robot’s pose pt = f(It, Dt; θ), where θ are
                the network parameters obtained with supervised training in simulation. The pose is defined as pt = [xt,
                yt, ɑt, βt ], two coordinates and two angles.

                <br/><br/>

                But first, are you able to solve this task?

                <br/><br/>

                <span style="font-style: italic">
                    Try to pinpoint the origin of the image on the right. To do so, click on the location where you think the image originated on the map and drag the appearing circle to adjust the orientation.
                </span>

            </p>
        </div>

    </div>


    <!--</div>-->
    <div class="row" style="text-align: center">
        <div class="three columns" style="margin-top: 2%;">

            <img id="guessimg" width="256" src="">
            <button id="guesser" style="margin-left: 25px"> Guess</button>
            <div style="text-align: left;margin-top: 60px;margin-left: 15px">
                <p style="text-underline: #555555;text-decoration: underline"> Score </p>
                <ul>
                    <li># of Guesses: <span id="nguess"></span></li>
                    <li> Avg Dist: <span id="avgDist"></span></li>
                    <!--                    <li> Avg Orr:</li>-->
                </ul>
            </div>
        </div>
        <div class="nine columns" style="margin-top: 2%;display: inline-block">

            <svg id="theo-guess" style="width: 100%;height: 580px;border: #555555 solid 1px"></svg>
        </div>


    </div>


    <div class="row">
        <div class="twelve column" style="margin-top: 10%">
            <h4 style="text-align: left"> Let's see how a model performs </h4>
            <p>
                We designed and trained posest, a convolutional deep learning model able to regress the coordinates and
                orientation of a given rgb & depth image.
            <p>

            <img src="assets/nn.png" style="width: 500px; border: none">
                Click here to have details on the model and it's training

            </p>

            </p>

            <p>
                In the figure bellow (right side), are represented the model's predictions of images (rgb & depth) from
                a
                trajectory starting in the living room, and ending in the laundry. Hovering those dots with the mouse
                will display the ground truth coordinates of those images and hence how wrong a prediction is. The color
                of each dot encodes the distance to the ground truth starting with green (close) to red, (far).
            </p>
            <p>
                On the left side, we can see a Umap projection of features extracted from nearly 12000 previously unseen
                images. Each dot is resprensts features of an image, and its color corresponds to which room this image
                is supposedly taken from based on predictions coordinates. In this view we can observe that the model is
                quite able to distinguish rooms, appart from ambiguities at the intersection of clusters. Thus we can
                conclude that the model properly learned to identify rooms.
            </p>


        </div>

    </div>
    <div class="row">
        <div class="twelve columns" style="margin-top: 8%;position: relative;height: 130px">
            <img src="" height="128" width="128" id="imgr" style="position: absolute">
            <img src="" height="128" width="128" id="depthr" style="position: absolute;left:130px; ">
            <img class="play" id="play1" style="width: 29px;position: absolute;left: 290px;top:40px"
                 src="assets/play-sign.svg">
            <input id="timeline" type="range" min="0" max="57" step="1" value="0"
                   style="position: absolute;left: 335px;top:52px;width: 450px">
            <p id="timelineTxt" style="position: absolute;left: 793px;top:43px"> 0 </p>


        </div>
    </div>
    <div class="row">

        <div class="six columns" style="margin-top: 1%">
            <!--            <svg id="proj" style="width: 100%;height: 530px;border: #555555 solid 1px"></svg>-->
            <svg id="allProj" style="width: 100%;height: 530px;border: #555555 solid 1px"></svg>
            <div style="text-align: center;color: rgba(0,0,0,0.5)">
                Umap projection of features 12000 images. Each dot represents an image classified by the model, and
                their color their estimated room derived from the model's predicted coordinates.
            </div>
        </div>
        <div class="six columns" style="margin-top: 1%">
            <svg id="loc" style="width: 100%;height: 370px;     border: none;margin-top: 84px"></svg>

        </div>
    </div>


    <!--    <div class="row">
            <div class="twelve column" style="margin-top: 2%">

                <p>
                    Overall, we can see on the Umap projection that despite some noise, the model learned in its features to
                    discretise images per rooms.
                <ul>
                    <li>
                        TODO: Full Umap of original model.
                    </li>
                </ul>


                </p>
            </div>
        </div>-->


    <div class="row">
        <div class="twelve column" style="margin-top: 10%">
            <h4 style="text-align: left"> However, such a model is noise sensitive.. </h4>
            <p>
                As mentioned in introduction, the point of such a model is to use images from a robot, and hence in
                a real-world environment with moving objects, luminosity changes and overall disparities with the
                simulation (e.g. physics). Those noises, referenced to as reality-gap, may have a huge impact on the
                model's prediction
                despite not being a difficulty for humans. As an illustration, the figure bellow depicts two captures
                from roughly the same orientation on coordinates. The images on the left side, sampled in the simulator
                tends to have a yellow luminosity (TO CHECK PHRASING) and overall different shades. In addition, the
                real camera does not have the same field of view and angle. The depth sensor does not have the same
                range as the simulated one. This results in an important shift of values (light gray) which can be
                interpreted as no obstacles ahead.
            </p>
            <div style="display: inline-block;text-align: center;width: 100%">
            </div>
            <div style="position: relative;margin-top: 5%;text-decoration: #555555 underline">
                <p style="position: absolute;left: 20%;top:-50px;width: 100px;text-decoration: #555555 underline">
                    Simulator</p>
                <p style="position: absolute;right: 20%;top:-50px;;width: 100px;text-decoration: #555555 underline">
                    Real</p>
            </div>
            <div style="display: inline;text-align: center">
                <img src="datasets/temp/rgb31.jpg">
                <img src="datasets/temp/depth31.jpg">

                <div style="border-left:2px solid #c4c4c4; height: 256px; display: inline-block;margin-left: 10px;margin-right: 10px "></div>
                <img src="datasets/realSal/depth31.jpg">
                <img src="datasets/realSal/rgb31.jpg">
            </div>

            <div style="position: relative;width: 100%">
                <p style="position: absolute;left: 128px;bottom:-50px;width: 100px"> rgb</p>
                <p style="position: absolute;left: 363px;bottom:-50px;width: 100px"> depth</p>

                <p style="position: absolute;right: 338px;bottom:-50px;width: 100px"> depth</p>
                <p style="position: absolute;right: 72px;bottom:-50px;width: 100px"> rgb</p>
            </div>

            <p style="margin-top: 7%">
                In the following figure, one can observe the influence
                disparities between real-world or noise can have on the model's prediction. On the left side of the
                figures are projected features from the given images (top) in the same Umap parametric space. Hence dots
                locations on those projection share the same meaning. We can also observe how some rooms are more
                affected than other by switching between trajectories. For instance, we can see that in trajectory [XX],
                the model ...

                Noises can also be changed such as [XX] which makes the model fail most of its prediction. Hence, one
                hypothesis to draw is that the model heavily rely on the depth to decides on images coordinates and
                orientations.

                As we can see bellow, most of the model's predictions are far from where they were sampled, and
                some are not even predicted outside the building.
            </p>
        </div>
    </div>

    <div class="row">
        <div class="twelve columns" style="margin-top: 8%;position: relative;height: 130px">
            <img src="" height="128" width="128" id="imgr2" style="position: absolute">
            <img src="" height="128" width="128" id="depthr2" style="position: absolute;left:130px; ">
            <img src="" height="128" width="128" id="imgb2" style="position: absolute;right: 0">
            <img src="" height="128" width="128" id="depthb2" style="position: absolute;right: 130px">


            <div style="position: absolute;left:470px; top: 65px">
                <label for="trajsel2">Trajectory</label>
                <select class="" id="trajsel2">
                    <option value="0">0</option>
                    <option value="1">1</option>
                    <option value="2">2</option>
                    <option value="3">3</option>
                    <option value="4">4</option>
                </select>
            </div>

            <div style="position: absolute;left:570px; top: 65px">
                <label for="noisel2">Noise</label>
                <select class="" id="noisel2">
                    <option value="gaussian">Gaussian</option>
                    <option value="edge">Edge-Enhancing</option>
                    <option value="brightness">Brightness</option>
                    <option value="pepper">Pepper</option>
                    <option value="sharpen">Sharpen</option>
                    <option value="trans">Transforms</option>
                    <option value="white">White balance</option>

                </select>
            </div>


            <img class="play" id="play2" style="width: 29px;position: absolute;left: 290px;top:40px"
                 src="assets/play-sign.svg">
            <input id="timeline2" type="range" min="0" max="57" step="1" value="0"
                   style="position: absolute;left: 335px;top:52px;width: 450px">
            <p id="timelineTxt2" style="position: absolute;left: 793px;top:43px"> 0 </p>
        </div>
    </div>


    <div class="row">
        <div class="six columns" style="margin-top: 3%">
            <svg id="proj2" style="width: 100%;height: 530px;border: #555555 solid 1px"></svg>
        </div>
        <div class="six columns" style="margin-top: 3%">
            <svg id="loc2" style="width: 100%;height: 370px;border: none;margin-top: 84px"></svg>
        </div>
        <div class="twelve columns" style="height: 140px" id="imband2"></div>
    </div>


    <div class="row">
        <div class="ten column" style="margin-top: 8%">
            <h4 style="text-align: left"> Domain Randomization to the rescue</h4>

            <p>
                To tackle such an issue, one can use Domain Randomization <a href="#ref2">[2]</a>. It consist in
                approaches focused on
                altering the simulator in order to force the agent to adapt to those changes and thus learn invariant
                features. The changes in the simulator can take many forms, such as visual data augmentation (e.g.
                gaussian noise, lighting, textures, colors balance) or changes on the simulator itself (e.g. camera
                position, orientation or field of view). Those
                changes are applied during the training phase of the agent, and as we observe bellow it improves the AI
                performances on unseen simulated images and real-images.
            </p>

            <div class="row">
                <div class="twelve columns" style="margin-top: 8%;position: relative;height: 130px">
                    <img src="" height="128" width="128" id="imgr3" style="position: absolute">
                    <img src="" height="128" width="128" id="depthr3" style="position: absolute;left:130px; ">
                    <img src="" height="128" width="128" id="imgb3" style="position: absolute;right: 0">
                    <img src="" height="128" width="128" id="depthb3" style="position: absolute;right: 130px">


                    <div style="position: absolute;left:470px; top: 65px">
                        <label for="trajsel3">Trajectory</label>
                        <select class="" id="trajsel3">
                            <option value="r">real</option>
                            <option value="0">0</option>
                            <option value="1">1</option>
                            <option value="2">2</option>
                            <option value="3">3</option>
                            <option value="4">4</option>
                        </select>
                    </div>

                    <div style="position: absolute;left:570px; top: 65px">
                        <label for="noisel3">Noise</label>
                        <select class="" id="noisel3">
                            <option value="gaussian">Gaussian</option>
                            <option value="edge">Edge-Enhancing</option>
                            <option value="brightness">Brightness</option>
                            <option value="pepper">Pepper</option>
                            <option value="sharpen">Sharpen</option>
                            <option value="trans">Transforms</option>
                            <option value="white">White balance</option>

                        </select>
                    </div>


                    <img class="play" id="play3" style="width: 29px;position: absolute;left: 290px;top:40px"
                         src="assets/play-sign.svg">
                    <input id="timeline3" type="range" min="0" max="57" step="1" value="0"
                           style="position: absolute;left: 335px;top:52px;width: 450px">
                    <p id="timelineTxt3" style="position: absolute;left: 793px;top:43px"> 0 </p>
                </div>
            </div>

        </div>
    </div>


    <div class="row">
        <div class="six columns" style="margin-top: 3%">
            <svg id="proj3" style="width: 100%;height: 530px;border: #555555 solid 1px"></svg>
        </div>
        <div class="six columns" style="margin-top: 3%;height: 100%;vertical-align: center">
            <svg id="loc3" style="width: 100%;height: 370px;     border: none;margin-top: 84px"></svg>
        </div>
        <div class="twelve columns" style="height: 140px" id="imband3"></div>
    </div>


    <!--    <div class="row" style="margin-top: 8%;position: relative;">

            <div class="six columns">
                <svg id="allProj2" style="width: 100%;height: 530px;border: #555555 solid 1px"></svg>
            </div>

            <div class="six columns">

                <p>
                    Hello There
                </p>

            </div>

        </div>-->


    <div class="row">
        <div class="twelve column" style="margin-top: 8%">
            <h4 style="text-align: left"> What must change in real-images?</h4>
            <p>
                Using backprogation of predictions, one can extract the gradient and build saliency maps which depicts
                the most influencial parts of the inputed image
            </p>
,
            <div>

                <img src="datasets/realSal/rgb31.jpg"/>
                <!--                        <img src="datasets/temp/rgb0.jpg"/>-->
                <img src="datasets/temp/rgb31.jpg"/>

                <div style="border-left:2px solid #c4c4c4; height: 256px; display: inline-block;margin-left: 10px;margin-right: 10px "></div>

                <img src="datasets/realSal/rgb0.jpg"/>
            </div>
            <div>
                <img src="datasets/realSal/sal31.jpg"/>
                <img src="datasets/temp/sal31.jpg"/>
                <div style="border-left:2px solid #c4c4c4; height: 256px; display: inline-block;margin-left: 10px;margin-right: 10px "></div>

                <img src="datasets/realSal/sal0.jpg"/>

            </div>

        </div>
    </div>


    <div class="row">
        <div class="twelve column" style="margin-top: 8%">
            <h4 style="text-align: left"> What can be improved ?</h4>
            <p>
            </p>

            <ul>
                <li>
                    Speak of domain adaptation
                </li>
                <li>

                </li>
            </ul>
        </div>
    </div>


    <div class="row" style="text-align: center">
        <div class="twelve columns" style="margin-top: 2%;display: inline-block">
            <div style=" text-align: left;margin-bottom: 50px">
                <h5>Authors</h5>
                <p><a href="https://theo-jaunet.github.io/">Théo Jaunet</a> (<a href="https://twitter.com/jaunet_theo">@jaunet_theo</a>),
                    <a href="http://romain.vuillemot.net/">Romain
                        Vuillemot</a> (<a href="https://twitter.com/romsson">@romsson</a>) and <a
                            href="https://perso.liris.cnrs.fr/christian.wolf/">Christian Wolf </a>(<a
                            href="https://twitter.com/chriswolfvision">@chriswolfvision</a>), at LIRIS lab Lyon -
                    France.
                </p>
                This work takes place in Théo jaunet's Ph.D. which is supported by a French Ministry Fellowship and the
                <a
                        href="https://projet.liris.cnrs.fr/mi2/"> M2I project</a>,
            </div>

        </div>
    </div>


    <div class="row">
        <h4>Citations</h4>
    </div>
    <div class="row">
        <div class="ten columns">
            <ol>
                <li style="color: rgba(0,0,0,0.9);" id="ref1">
                    Deep Reinforcement Learning on a Budget: 3D Control and Reasoning Without a Supercomputer [<a
                        href="https://arxiv.org/abs/1904.01806">URL</a>].
                    <div style="color: rgba(0,0,0,0.5);margin-left: 15px">
                        Edward Beeching, Christian Wolf, Jilles Dibangoye and Olivier Simonin<br>
                        International Conference on Pattern Recognition (ICPR), 2020<br>
                    </div>
                </li>

                <li style="color: rgba(0,0,0,0.9);" id="ref2">
                    Domain
                    randomization for transferring deep neural networks from simulation to the real world. [<a
                        href="https://arxiv.org/abs/1703.06907">URL</a>]
                    <div style="color: rgba(0,0,0,0.5);margin-left: 15px">
                        Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, Pieter Abbeel <br/>
                        IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2017
                    </div>
                </li>


            </ol>
        </div>

    </div>
</div>


<script>
    // const data = fakedata(200);
    let dato;
    let dato2;
    let dato3;

    let tref;

    let dator;
    let idSel = [];

    let elements;
    let elements2;

    let elements3;
    let elements4;

    let elements5;
    let elements6;

    let curStep0 = 0;

    let curStep = 0;
    let curTraj = "0";
    let curNoise = "gaussian";


    let curStep2 = 0;
    let curTraj2 = "0";
    let curNoise2 = "gaussian";

    let pl = false;
    let timer = null;
    let timer2 = null;
    let timer3 = null;

    let rotSt = false;
    let guessid;

    let nguess = 0
    let avgDist = 0
    let avgOrr = 0


    let guessw = true

    const proj = d3.select("#proj");
    const loc = d3.select("#loc");

    const proj2 = d3.select("#proj2");
    const loc2 = d3.select("#loc2");


    const proj3 = d3.select("#proj3");
    const loc3 = d3.select("#loc3");

    let p1 = [[-5.994728088378906, 16.698274612426758], [-4.038941860198975, 14.940378189086914]];
    let proj_xscacle = d3.scaleLinear().domain(p1[0]).range([20, 515]); // Scale to Change based on SVG Size
    let proj_yscacle = d3.scaleLinear().domain(p1[1]).range([20, 515]);

    let colscale = d3.scaleLinear().domain([0, 20]).range(['green', 'red']);
    let tsvg = d3.select("#theo-guess");


    $("#guesser").on("click", function () {

        if (rotSt) {

            d3.select("#guessLine").remove();
            d3.select("#guessCr").remove();


            let txscale = d3.scaleLinear(simW, [50, 750])
            let tyscale = d3.scaleLinear(simH, [25, 545])
            // const coords = d3.mouse(tsvg.node());


            let tx = txscale(dato[guessid].tx);
            let ty = tyscale(dato[guessid].ty);
            let torr = dato[guessid].torr;

            nguess += 1;

            let el = $("#guess");

            $("#guesser").html("Try again!")
            $("#nguess").html(nguess);

            avgDist += euclidian_dist([tx, ty], [el.attr("ox"), el.attr("oy")]);
            $("#avgDist").html(Math.round(avgDist / nguess));


            tsvg.append("path")
                .attr("id", "gtpath")
                .attr("fill", "green")
                .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                .attr("transform", d => {
                        return "rotate(" + (180 - torr) + " " + (tx - 6) + " " + (ty - 6) + ") translate(" + (tx - 32) + "," + (ty - 32) + ")"
                    }
                );


            tsvg.append("line")
                .attr("x1", tx - 5)
                .attr("x2", el.attr("ox") - 5)
                .attr("y2", el.attr("oy") - 5)
                .attr("y1", ty - 5)
                .attr("stroke", "#333333")
                .attr("stroke-width", "2")
                .attr("stroke-dasharray", "6,2")

            d3.select("#guess").transition().duration(100).style("fill", "#333333")
                .attr("id", "")
            rotSt = false;
        } else {


            const introsvg = d3.select("#theo-guess")


            introsvg.selectAll("path").remove()
            introsvg.selectAll("line").remove()

            guessid = getRandomInt(0, tref.length - 1);

            $("#guessimg").attr("src", "data:image/jpeg;base64," + tref[guessid].imgR);

            $("#guesser").html("Guess")

        }


    });


    tsvg.on("click", function (e) {

        if (!rotSt) {
            // console.log(e);0
            rotSt = true;
            const coords = d3.mouse(tsvg.node());

            //
            // tsvg.append("circle")
            //     .attr("id", "guess")
            //     .attr("cx", coords[0])
            //     .attr("cy", coords[1])
            //     .attr("ty", coords[1])
            //     .attr("tx", coords[0])
            //     .attr("r", "5")
            //     .attr("fill", "steelblue")


            tsvg.append("line")
                .attr("id", "guessLine")
                .attr("x1", coords[0] - 5)
                .attr("x2", coords[0] - 5)
                .attr("y1", coords[1] - 8)
                .attr("y2", coords[1] + 40)
                .attr("stroke", 'red')
                .attr("stroke-width", "3")
                .attr("stroke-dasharray", "6,2");


            tsvg.append("path")
                .attr("id", "guess")
                .attr("num", 0)
                .attr("tx", coords[0])
                .attr("ty", coords[1])
                .attr("ox", coords[0])
                .attr("oy", coords[1])
                .attr("thor", 0)
                .attr("tr", 0)
                .attr("fill", "steelblue")
                .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                .attr("transform", "rotate(" + (0) + " " + (coords[0] - 6) + " " + (coords[1] - 6) + ") translate(" + (coords[0] - 32) + "," + (coords[1] - 32) + ")  ")
                .call(d3.drag()
                    .on("start", dragstarted)
                    .on("drag", dragged)
                    .on("end", dragended));


            tsvg.append("circle")
                .attr("id", "guessCr")
                .attr("cx", coords[0] - 5)
                .attr("cy", coords[1] + 40)
                .attr("r", 6)
                .attr("fill", "steelblue")

                .call(d3.drag()
                    .on("start", dragstarted2)
                    .on("drag", dragged2)
                    .on("end", dragended2));

            /*            .attr("stroke", 'red')
                    .attr("stroke-width", "3")
                    .attr("stroke-dasharray", "6,2")*/

        }
    });


    function dragstarted(d) {
        d3.select(this).raise().attr("stroke", "black");
    }

    function dragged(d) {
        const point = d3.mouse(tsvg.node());

        let path = d3.select("#guess");
        let line = d3.select("#guessLine");
        let circle = d3.select("#guessCr");

        console.log(point);


        let deltax = parseFloat(point[0] - path.attr("ox"));
        let deltay = parseFloat(point[1] - path.attr("oy"));


        path.attr("ox", point[0]);
        path.attr("oy", point[1]);

        path.transition().duration(15).attr("transform", "rotate(" + (path.attr("thor")) + " " + (point[0] - 6) + " " + (point[1] - 6) + ") translate(" + (point[0] - 32) + "," + (point[1] - 30) + ")  ")

        circle.attr("cx", parseFloat(circle.attr("cx")) + deltax);
        circle.attr("cy", parseFloat(circle.attr("cy")) + deltay);


        line.transition().duration(15).attr("x2", parseFloat(circle.attr("cx")) + deltax).attr("y2", parseFloat(circle.attr("cy")) + deltay).attr("x1", point[0] - 5).attr("y1", point[1] - 8)
        // if ((point[0] > 0 && point[0] < 340) && (point[1] > 0 && point[1] < 340))
        //     circle.attr("cx", point[0]).attr("cy", point[1]);
    }

    function dragended(d) {
        d3.select(this).attr("stroke", null);
    }


    function dragstarted2(d) {
        d3.select(this).raise().attr("stroke", "black");
    }

    function dragged2(d) {
        const point = d3.mouse(tsvg.node());

        let path = d3.select("#guess");
        let line = d3.select("#guessLine");
        let circle = d3.select("#guessCr");

        console.log(point);


        // let deltax = parseFloat(point[0] - path.attr("ox"));
        // let deltay = parseFloat(point[1] - path.attr("oy"));

        //
        // path.attr("ox", point[0])
        // path.attr("oy", point[1])


        const orr = -90 + (Math.atan2(point[1] - path.attr("oy"), (point[0] - path.attr("ox"))) * (180 / Math.PI));

        path.attr("thor", orr)

        path.transition().duration(15).attr("transform", "rotate(" + (orr) + " " + (path.attr("ox") - 6) + " " + (path.attr("oy") - 6) + ") translate(" + (path.attr("ox") - 32) + "," + (path.attr("oy") - 32) + ")  ")
        circle.transition().duration(15).attr("cx", parseFloat(point[0])).attr("cy", parseFloat(point[1]));
        line.transition().duration(15).attr("x2", parseFloat(point[0])).attr("y2", parseFloat(point[1]));
        // circle.transition().duration(15)

        // if ((point[0] > 0 && point[0] < 340) && (point[1] > 0 && point[1] < 340))
        //     circle.attr("cx", point[0]).attr("cy", point[1]);
    }

    function dragended2(d) {
        d3.select(this).attr("stroke", null);
    }


    loadmap(d3.select("#theo-guess"), 'assets/images/map.jpg');
    loadmap(d3.select("#loc2"), 'assets/images/map.jpg');
    loadmap(d3.select("#loc3"), 'assets/images/map.jpg');

    $("#timeline").on("input", function () {

        let step = $(this).val();
        let ell = dato[step];
        curStep0 = parseInt(step);

        $("#imgr").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
        $("#depthr").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

        $("#imgb").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
        $("#depthb").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

        $("#timelineTxt").html(step)

        update_time();

        let inside = d3.selectAll("path")

        inside.filter(d => {
            return d.id > curStep0
        }).transition().duration(20).style("opacity", '0.1');


        inside.filter(d => {
            return d.id <= curStep0
        }).transition().duration(20).style("opacity", '1')

    });


    $("#timeline2").on("input", function () {

        let step = $(this).val();
        let ell = dato2[step];
        curStep = parseInt(step);

        $("#imgr2").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
        $("#depthr2").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

        $("#imgb2").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
        $("#depthb2").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

        $("#timelineTxt2").html(step2)

        update_time2();

        let inside = d3.selectAll("path")

        inside.filter(d => {
            return d.id > curStep
        }).transition().duration(20).style("opacity", '0.1');


        inside.filter(d => {
            return d.id <= curStep
        }).transition().duration(20).style("opacity", '1')

    });


    $("#timeline3").on("input", function () {

        let step = $(this).val();
        let ell = dato3[step];
        curStep2 = parseInt(step);

        $("#imgr3").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
        $("#depthr3").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

        $("#imgb3").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
        $("#depthb3").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

        $("#timelineTxt3").html(step3)

        update_time3();

        let inside = d3.selectAll("path")

        inside.filter(d => {
            return d.id > curStep2
        }).transition().duration(20).style("opacity", '0.1');


        inside.filter(d => {
            return d.id <= curStep2
        }).transition().duration(20).style("opacity", '1')

    });


    $('#play1').on('click', function () {

        pl = !pl;
        if (pl) {
            if (curStep0 >= dato.length)
                curStep0 = 0
            $(this).attr('src', 'assets/round-pause-button.svg');

            timer = setInterval(step, 115);
            step()
        } else {
            $(this).attr('src', 'assets/play-sign.svg');
            clearInterval(timer);
            timer = null
        }
    });


    $('#play2').on('click', function () {

        pl = !pl;
        if (pl) {
            if (curStep >= dato2.length)
                curStep = 0
            $(this).attr('src', 'assets/round-pause-button.svg');

            timer2 = setInterval(step2, 115);
            step2()
        } else {
            $(this).attr('src', 'assets/play-sign.svg');
            clearInterval(timer2);
            timer2 = null
        }
    });


    $('#play3').on('click', function () {

        pl = !pl;
        if (pl) {
            if (curStep2 >= dato3.length)
                curStep2 = 0
            $(this).attr('src', 'assets/round-pause-button.svg');

            timer3 = setInterval(step3, 115);
            step3()
        } else {
            $(this).attr('src', 'assets/play-sign.svg');
            clearInterval(timer3);
            timer3 = null
        }
    });


    function update_time() {

        let tbar = $('#timeline');

        let val = (tbar.val() - tbar.attr('min')) / (tbar.attr('max') - tbar.attr('min'));

        tbar.css('background-image',
            '-webkit-gradient(linear, left top, right top, '
            + 'color-stop(' + val + ', #233E34), '
            + 'color-stop(' + val + ', #C5C5C5)'
            + ')'
        );
    }


    function update_time2() {

        let tbar = $('#timeline2');

        let val = (tbar.val() - tbar.attr('min')) / (tbar.attr('max') - tbar.attr('min'));

        tbar.css('background-image',
            '-webkit-gradient(linear, left top, right top, '
            + 'color-stop(' + val + ', #233E34), '
            + 'color-stop(' + val + ', #C5C5C5)'
            + ')'
        );
    }

    function update_time3() {

        let tbar = $('#timeline3');

        let val = (tbar.val() - tbar.attr('min')) / (tbar.attr('max') - tbar.attr('min'));

        tbar.css('background-image',
            '-webkit-gradient(linear, left top, right top, '
            + 'color-stop(' + val + ', #233E34), '
            + 'color-stop(' + val + ', #C5C5C5)'
            + ')'
        );
    }


    function step2() {

        curStep += 1;
        let ell = dato2[curStep];


        if (ell) {
            $("#imgr2").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
            $("#depthr2").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

            $("#imgb2").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
            $("#depthb2").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

            $("#timelineTxt2").html(curStep)

            $("#timeline2").val(curStep);

            update_time2()


            let inside = d3.selectAll("path")


            inside.filter(d => {
                return d.id > curStep
            }).transition().duration(20).style("opacity", '0.1')


            inside.filter(d => {
                return d.id <= curStep
            }).transition().duration(20).style("opacity", '1')

        } else {
            pl = false;
            $('#play2 ').attr('src', 'assets/play-sign.svg');
            curStep = 0;
            clearInterval(timer2);
            timer2 = null
        }

    }


    function step3() {

        curStep2 += 1;
        let ell = dato3[curStep2];


        if (ell) {
            $("#imgr3").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
            $("#depthr3").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

            $("#imgb3").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
            $("#depthb3").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

            $("#timelineTxt3").html(curStep2)

            $("#timeline3").val(curStep2);

            update_time3()


            let inside = d3.selectAll("path")


            inside.filter(d => {
                return d.id > curStep2
            }).transition().duration(20).style("opacity", '0.1')


            inside.filter(d => {
                return d.id <= curStep2
            }).transition().duration(20).style("opacity", '1')

        } else {
            pl = false;
            $('#play3 ').attr('src', 'assets/play-sign.svg');
            curStep2 = 0;
            clearInterval(timer3);
            timer3 = null
        }

    }


    function step() {

        curStep0 += 1;
        let ell = dato[curStep0];


        if (ell) {
            $("#imgr").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
            $("#depthr").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

            $("#imgb2").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
            $("#depthb2").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

            $("#timelineTxt").html(curStep0)

            $("#timeline").val(curStep0);

            update_time()


            let inside = d3.selectAll("path")


            inside.filter(d => {
                return d.id > curStep0
            }).transition().duration(20).style("opacity", '0.1')


            inside.filter(d => {
                return d.id <= curStep0
            }).transition().duration(20).style("opacity", '1')

        } else {
            pl = false;
            $('#play1').attr('src', 'assets/play-sign.svg');
            curStep0 = 0;
            clearInterval(timer);
            timer = null
        }

    }


    const cirhov = proj.append("circle")
        .attr("id", "projHov")
        .attr("stroke", "#333333")
        .attr("stroke-width", "1")
        .attr("fill", "none")
        .attr("r", "24");

    const cirhov2 = loc.append("circle")
        .attr("id", "locHov")
        .attr("stroke", "#333333")
        .attr("stroke-width", "1")
        .attr("fill", "none")
        .attr("r", "24");


    const cirhov3 = proj2.append("circle")
        .attr("id", "locHov")
        .attr("stroke", "#333333")
        .attr("stroke-width", "1")
        .attr("fill", "none")
        .attr("r", "24");

    const cirhov4 = loc2.append("circle")
        .attr("id", "locHov")
        .attr("stroke", "#333333")
        .attr("stroke-width", "1")
        .attr("fill", "none")
        .attr("r", "24");

    const cirhov5 = proj3.append("circle")
        .attr("id", "locHov")
        .attr("stroke", "#333333")
        .attr("stroke-width", "1")
        .attr("fill", "none")
        .attr("r", "24");

    const cirhov6 = loc3.append("circle")
        .attr("id", "locHov")
        .attr("stroke", "#333333")
        .attr("stroke-width", "1")
        .attr("fill", "none")
        .attr("r", "24");


    $("#trajsel2").on("change", function () {

        curTraj = $("#trajsel2").val();

        getData1("datasets/basic/" + curTraj + "_" + curNoise + ".json").then(function () {

            proj2.selectAll("path").remove();
            proj2.selectAll("line").remove();
            loc2.selectAll("path").remove();
            loc2.selectAll("line").remove();

            dato2.sort((a, b) => {

                if (a.id > b.id) {
                    return 1
                } else {
                    return -1
                }

            });


            let elem = dato2.filter(d => d.id === 0)[0];


            $("#imgr2").attr("src", 'data:image/jpeg;base64,' + elem.imgR)
            $("#depthr2").attr("src", 'data:image/jpeg;base64,' + elem.depthR)

            $("#imgb2").attr("src", 'data:image/jpeg;base64,' + elem.imgB)
            $("#depthb2").attr("src", 'data:image/jpeg;base64,' + elem.depthB)


            drawPoints(dato2, proj2);
            drawElements(dato2, loc2);

            elements3 = proj2.selectAll(".projDot");
            elements4 = loc2.selectAll(".locDot");

            $("#timeline2").attr("max", dato2.length - 1)
        });

    })


    $("#trajsel3").on("change", function () {


        curTraj2 = $("#trajsel3").val();


        if (curTraj2 !== "r") {
            getData2("datasets/traj" + curTraj2 + "/" + curTraj2 + "_" + curNoise2 + ".json").then(function () {

                proj3.selectAll("path").remove();
                proj3.selectAll("line").remove();
                loc3.selectAll("path").remove();
                loc3.selectAll("line").remove();

                dato3.sort((a, b) => {

                    if (a.id > b.id) {
                        return 1
                    } else {
                        return -1
                    }

                });

                let elem = dato3.filter(d => d.id === 0)[0];

                // console.log(elem);

                $("#imgr3").attr("src", 'data:image/jpeg;base64,' + elem.imgR)
                $("#depthr3").attr("src", 'data:image/jpeg;base64,' + elem.depthR)

                $("#imgb3").attr("src", 'data:image/jpeg;base64,' + elem.imgB)
                $("#depthb3").attr("src", 'data:image/jpeg;base64,' + elem.depthB)


                drawPoints(dato3, proj3);
                drawElements(dato3, loc3);

                elements5 = proj3.selectAll(".projDot");
                elements6 = loc3.selectAll(".locDot");

                $("#timeline3").attr("max", dato3.length - 1)
            });
        } else {


            getData2("datasets/cbon.json").then(function () {

                proj3.selectAll("path").remove();
                proj3.selectAll("line").remove();
                loc3.selectAll("path").remove();
                loc3.selectAll("line").remove();

                dato3.sort((a, b) => {

                    if (a.id > b.id) {
                        return 1
                    } else {
                        return -1
                    }

                });

                let elem = dato3.filter(d => d.id === 0)[0];
                let telem = tref.filter(d => d.id === 0)[0];

                // console.log(elem);

                $("#imgr3").attr("src", 'data:image/jpeg;base64,' + telem.imgR)
                $("#depthr3").attr("src", 'data:image/jpeg;base64,' + telem.depthR)

                $("#imgb3").attr("src", 'data:image/jpeg;base64,' + elem.imgR)
                $("#depthb3").attr("src", 'data:image/jpeg;base64,' + elem.depthR)


                drawPoints(dato3, proj3);
                drawElements(dato3, loc3);

                elements5 = proj3.selectAll(".projDot");
                elements6 = loc3.selectAll(".locDot");

                $("#timeline3").attr("max", dato3.length - 1)
            });

        }
    })


    $("#noisel2").on("change", function () {

        // console.log($("#trajsel").val());

        curNoise = $("#noisel2").val();

        getData1("datasets/basic/" + curTraj + "_" + curNoise + ".json").then(function () {


            proj2.selectAll("path").remove();
            proj2.selectAll("line").remove();
            loc2.selectAll("path").remove();
            loc2.selectAll("line").remove();

            dato2.sort((a, b) => {

                if (a.id > b.id) {
                    return 1
                } else {
                    return -1
                }

            });


            let elem = dato2.filter(d => d.id === 0)[0];


            $("#imgr2").attr("src", 'data:image/jpeg;base64,' + elem.imgR);
            $("#depthr2").attr("src", 'data:image/jpeg;base64,' + elem.depthR);

            $("#imgb2").attr("src", 'data:image/jpeg;base64,' + elem.imgB);
            $("#depthb2").attr("src", 'data:image/jpeg;base64,' + elem.depthB);


            drawPoints(dato2, proj2);
            drawElements(dato2, loc2);

            elements3 = proj2.selectAll(".projDot");
            elements4 = loc2.selectAll(".locDot");
            $("#timeline2").attr("max", dato2.length - 1)

        });
    })


    $("#noisel3").on("change", function () {

        // console.log($("#trajsel").val());

        curNoise2 = $("#noisel3").val();

        getData2("datasets/traj" + curTraj2 + "/" + curTraj2 + "_" + curNoise2 + ".json").then(function () {


            proj3.selectAll("path").remove();
            proj3.selectAll("line").remove();
            loc3.selectAll("path").remove();
            loc3.selectAll("line").remove();

            dato3.sort((a, b) => {

                if (a.id > b.id) {
                    return 1
                } else {
                    return -1
                }

            });


            let elem = dato3.filter(d => d.id === 0)[0];


            console.log(elem);

            $("#imgr3").attr("src", 'data:image/jpeg;base64,' + elem.imgR);
            $("#depthr3").attr("src", 'data:image/jpeg;base64,' + elem.depthR);

            $("#imgb3").attr("src", 'data:image/jpeg;base64,' + elem.imgB);
            $("#depthb3").attr("src", 'data:image/jpeg;base64,' + elem.depthB);


            drawPoints(dato3, proj3);
            drawElements(dato3, loc3);

            elements5 = proj3.selectAll(".projDot");
            elements6 = loc3.selectAll(".locDot");
            $("#timeline3").attr("max", dato3.length - 1)

        });
    })


    function getRandomInt(min, max) {
        min = Math.ceil(min);
        max = Math.floor(max);
        return Math.floor(Math.random() * (max - min + 1)) + min;
    }


    getRef("datasets/traj" + 0 + "/" + 0 + "_gaussian.json").then(function () {
    })

    getData0("datasets/traj" + curTraj + "/" + curTraj + "_" + curNoise + ".json").then(function () {

        /*
                proj2.selectAll("path").remove();
                proj2.selectAll("line").remove();
                loc2.selectAll("path").remove();
                loc2.selectAll("line").remove();


                proj3.selectAll("path").remove();
                proj3.selectAll("line").remove();
                loc3.selectAll("path").remove();
                loc3.selectAll("line").remove();*/


        guessid = getRandomInt(0, dato.length - 1)
        // guessid = 54
        // guessid = 5
        $("#guessimg").attr("src", "data:image/jpeg;base64," + dato[guessid].imgR)

        $("#timeline").attr("max", dato.length)
        dato.sort((a, b) => {

            if (a.id > b.id) {
                return 1
            } else {
                return -1
            }
        });
        console.log(dato);

        let elem = dato.filter(d => d.id === 0)[0];

        console.log(elem);

        $("#imgr").attr("src", 'data:image/jpeg;base64,' + elem.imgR)
        $("#depthr").attr("src", 'data:image/jpeg;base64,' + elem.depthR)

        $("#imgb").attr("src", 'data:image/jpeg;base64,' + elem.imgB)
        $("#depthb").attr("src", 'data:image/jpeg;base64,' + elem.depthB)


        drawPoints(dato, proj);
        drawElements(dato, loc);

        elements = proj.selectAll(".projDot");
        elements2 = loc.selectAll(".locDot");


    });


    getData1("datasets/basic/" + curTraj + "_" + curNoise + ".json").then(function () {


        $("#timeline2").attr("max", dato2.length)
        dato2.sort((a, b) => {

            if (a.id > b.id) {
                return 1
            } else {
                return -1
            }
        });


        let elem = dato2.filter(d => d.id === 0)[0];

        $("#imgr2").attr("src", 'data:image/jpeg;base64,' + elem.imgR);
        $("#depthr2").attr("src", 'data:image/jpeg;base64,' + elem.depthR);

        $("#imgb2").attr("src", 'data:image/jpeg;base64,' + elem.imgB);
        $("#depthb2").attr("src", 'data:image/jpeg;base64,' + elem.depthB);


        drawPoints(dato2, proj2);
        drawElements(dato2, loc2);


        elements3 = proj2.selectAll(".projDot");
        elements4 = loc2.selectAll(".locDot");

    });


    getData2("datasets/traj" + curTraj + "/" + curTraj + "_" + curNoise + ".json").then(function () {


        $("#timeline3").attr("max", dato3.length)
        dato3.sort((a, b) => {

            if (a.id > b.id) {
                return 1
            } else {
                return -1
            }
        });


        let elem = dato3.filter(d => d.id === 0)[0];

        $("#imgr3").attr("src", 'data:image/jpeg;base64,' + elem.imgR)
        $("#depthr3").attr("src", 'data:image/jpeg;base64,' + elem.depthR)

        $("#imgb3").attr("src", 'data:image/jpeg;base64,' + elem.imgB)
        $("#depthb3").attr("src", 'data:image/jpeg;base64,' + elem.depthB)


        drawPoints(dato3, proj3);
        drawElements(dato3, loc3);

        elements5 = proj3.selectAll(".projDot");
        elements6 = loc3.selectAll(".locDot");


    });


    // debugInit();


    function debugInit() {
        loadmap(loc, 'assets/images/map.jpg');
        drawPoints(data, proj);
        drawElements(data, d3.select("#loc"));
    }

    async function getData0(url) {
        dato = await d3.json(url).then(d => {
            return JSON.parse(d.replace(/'/g, '"'))
        });
    }

    async function getData1(url) {
        dato2 = await d3.json(url).then(d => {
            return JSON.parse(d.replace(/'/g, '"'))
        });
    }

    async function getData2(url) {
        dato3 = await d3.json(url).then(d => {
            return JSON.parse(d.replace(/'/g, '"'))
        });
    }


    async function getRef(url) {
        tref = await d3.json(url).then(d => {
            return JSON.parse(d.replace(/'/g, '"'))
        });
    }


    async function getUmap(url) {
        dator = await d3.json(url).then(d => {
            return JSON.parse(d.replace(/'/g, '"'))
        });
    }


    getUmap("umapout.json").then(function () {
            var color = d3.scaleOrdinal(d3.schemeCategory10);

            // p1 = [d3.extent(dator["umap"].map(d => d[0])), d3.extent(dator["umap"].map(d => d[1]))];


            console.log([d3.extent(dator["umap"].map(d => d[0])), d3.extent(dator["umap"].map(d => d[1]))]);

            console.log(p1);

            let tbo = d3.select("#allProj")

            let dxscale = d3.scaleLinear().domain(p1[0]).range([20, 515]); // Scale to Change based on SVG Size
            let dyscale = d3.scaleLinear().domain(p1[1]).range([20, 515]);

            let rooms = ["Uncertain", "RoomTheo", "RoomMate", "LivingRoom", "Laundry", "Kitchen", "Corridor", "Bathroom", "Hall"]

            console.log(dator["umap"].length);

            for (let i = 0; i < dator["umap"].length; i++) {

                tbo.append("circle")
                    .attr("cx", dxscale(dator["umap"][i][0]))
                    .attr("cy", dyscale(dator["umap"][i][1]))
                    .attr("r", 2)
                    .attr('fill', color(dator["rooms"][i]))
            }

            for (let i = 0; i < 9; i++) {

                tbo.append("circle")
                    .attr("cx", 500)
                    .attr("cy", 345 + (20 * i))
                    .attr("r", 5)
                    .attr("fill", color(i));

                tbo.append("text")
                    .attr("text-anchor", "end")
                    .attr("x", 487)
                    .attr("y", 350 + (20 * i))
                    .text(rooms[i])

            }

        }
    )


    /* getUmap("umapout.json").then(function () {

         var color = d3.scaleOrdinal(d3.schemeCategory10);

         let p1 = [d3.extent(dator["umap"].map(d => d[0])), d3.extent(dator["umap"].map(d => d[1]))];

         let tbo2 = d3.select("#allProj2")

         let dxscale2 = d3.scaleLinear().domain(p1[0]).range([20, 515]); // Scale to Change based on SVG Size
         let dyscale2 = d3.scaleLinear().domain(p1[1]).range([20, 515]);


         let rooms = ["Uncertain", "RoomTheo", "RoomMate", "LivingRoom", "Laundry", "Kitchen", "Corridor", "Bathroom", "Hall"]

         console.log(dator);

         for (let i = 0; i < dator["umap"].length; i++) {

             tbo2.append("circle")
                 .attr("cx", dxscale2(dator["umap"][i][0]))
                 .attr("cy", dyscale2(dator["umap"][i][1]))
                 .attr("r", 2)
                 .attr('fill', color(dator["rooms"][i]))
         }


         for (let i = 0; i < 9; i++) {

             tbo2.append("circle")
                 .attr("cx", 510)
                 .attr("cy", (510) - (20 * i))
                 .attr("r", 5)
                 .attr("fill", color(i));

             tbo2.append("text")
                 .attr("text-anchor", "end")
                 .attr("x", 500)
                 .attr("y", (515) - (20 * i))
                 .text(rooms[i])
         }
     });
 */

    function loadmap(svg, map) {

        svg.append('image')
            .attr('xlink:href', map)
            .attr('x', -40)
            .attr('y', -15)
            .style('width', '110%').moveToBack()
    }

    function handleCirHovSyncLoc(cirhov, coords, elements, elements2, loc, proj) {

        cirhov.transition().duration(25).attr("transform", "translate(" + coords[0] + ", " + coords[1] + ")")
        if (elements2) {
            let inside = elements2.filter(d => {
                return euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], coords) < 25
            });

            inside.transition().duration(5).attr("fill", "purple");
            elements2.filter(d => {
                return euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], coords) > 24
            }).transition().duration(5).attr("fill", (d) => colscale(euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], [loc_xscacle(d.lx2), loc_yscacle(d.ly2)])))

        }

        // console.log(inside);


        let inside2 = elements.filter(d => {
            return euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], coords) < 25
        });

        // console.log(elements2);
        inside2.transition().duration(5).attr("fill", "purple");


        elements.filter(d => {
            return euclidian_dist([loc_xscacle(d.px1), loc_yscacle(d.py1)], coords) > 24
        }).transition().duration(5).attr("fill", (d) => colscale(euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], [proj_xscacle(d.px2), proj_yscacle(d.py2)])))


        elements.each((d) => {

            // console.log(d);
            if (euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], coords) < 25) {

                if (!idSel.includes(d.id)) {
                    const orr = 180 - (Math.atan2(proj_yscacle(d.py1) - proj_yscacle(d.py2), proj_xscacle(d.px1) - proj_xscacle(d.px2)) * (180 / Math.PI));
                    const orr2 = 180 - (Math.atan2(loc_yscacle(d.ly1) - loc_yscacle(d.ly2), loc_xscacle(d.lx1) - loc_xscacle(d.lx2)) * (180 / Math.PI));

                    proj.append("path")
                        .attr("class", "tbrm")
                        // .style("transform-origin", "50% 50%")
                        .attr("num", d.id)
                        .attr("fill", "steelblue")
                        .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                        .attr("transform", "rotate(" + (orr) + " " + (proj_xscacle(d.px2) - 2) + " " + (proj_yscacle(d.py2) - 2) + ") translate(" + (proj_xscacle(d.px2) - 16) + "," + (proj_yscacle(d.py2) - 16) + ")  scale(0.5) ")

                    loc.append("path")
                        .attr("class", "tbrm")
                        .attr("num", d.id)
                        .attr("fill", "steelblue")
                        .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                        .attr("transform", "rotate(" + (orr2) + " " + (loc_xscacle(d.lx2) - 2) + " " + (loc_yscacle(d.ly2) - 2) + ") translate(" + (loc_xscacle(d.lx2) - 16) + "," + (loc_yscacle(d.ly2) - 16) + ")  scale(0.5) ")
                    // .attr("transform", "rotate(180 64 62) translate(50 50) scale(0.5)")

                    idSel.push(d.id)

                    let tpath = proj.append("line")
                        .attr("class", "tbrm")
                        .attr("num", d.id)
                        .attr("x1", proj_xscacle(d.px1))
                        .attr("y1", proj_yscacle(d.py1))
                        .attr("x2", proj_xscacle(d.px2))
                        .attr("y2", proj_yscacle(d.py2))
                        .attr('stroke', 'steelblue')
                        .style('stroke-width', '3px')

                    let totalLength = tpath.node().getTotalLength();

                    tpath.attr("stroke-dasharray", totalLength + " " + totalLength)
                        .attr("stroke-dashoffset", totalLength)
                        .transition()
                        .duration(250)
                        .attr("stroke-dashoffset", 0);


                    let tpath2 = loc.append("line")
                        .attr("class", "tbrm")
                        .attr("num", d.id)
                        .attr("x1", loc_xscacle(d.lx1))
                        .attr("y1", loc_yscacle(d.ly1))
                        .attr("x2", loc_xscacle(d.lx2))
                        .attr("y2", loc_yscacle(d.ly2))
                        .attr('stroke', 'steelblue')
                        .style('stroke-width', '3px')

                    let totalLength2 = tpath2.node().getTotalLength();

                    tpath2.attr("stroke-dasharray", totalLength2 + " " + totalLength2)
                        .attr("stroke-dashoffset", totalLength2)
                        .transition()
                        .duration(250)
                        .attr("stroke-dashoffset", 0)

                }
            } else {
                let tid = idSel.indexOf(d.id);
                if (tid) {
                    idSel.splice(tid)
                    d3.selectAll('.tbrm[num="' + d.id + '"]').remove()

                }

            }
        })
    }


    function handleCirHovSyncProj(cirhov, coords, elements, elements2, loc, proj) {


        cirhov.transition().duration(25).attr("transform", "translate(" + coords[0] + ", " + coords[1] + ")")


        let inside = elements.filter(d => {
            return euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], coords) < 25 && d.id < curStep
        });
        inside.transition().duration(5).attr("fill", "purple");

        let inside2 = elements2.filter(d => {
            return euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], coords) < 25 && d.id < curStep
        });
        inside2.transition().duration(5).attr("fill", "purple");

        elements2.filter(d => {
            return euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], coords) > 24 && d.id < curStep
        }).transition().duration(5).attr("fill", (d) => colscale(euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], [loc_xscacle(d.lx2), loc_yscacle(d.ly2)])))


        elements.filter(d => {
            return euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], coords) > 24 && d.id < curStep
        }).transition().attr("fill", (d) => colscale(euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], [proj_xscacle(d.px2), proj_yscacle(d.py2)])))


        elements.each((d) => {

            // console.log(d);
            if (euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], coords) < 25 && d.id < curStep) {

                if (!idSel.includes(d.id)) {
                    const orr = 180 - (Math.atan2(proj_yscacle(d.py1) - proj_yscacle(d.py2), proj_xscacle(d.px1) - proj_xscacle(d.px2)) * (180 / Math.PI));
                    const orr2 = 180 - (Math.atan2(loc_yscacle(d.ly1) - loc_yscacle(d.ly2), loc_xscacle(d.lx1) - loc_xscacle(d.lx2)) * (180 / Math.PI));

                    proj.append("path")
                        .attr("class", "tbrm")
                        // .style("transform-origin", "50% 50%")
                        .attr("num", d.id)
                        .attr("fill", "steelblue")
                        .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                        .attr("transform", "rotate(" + (orr) + " " + (proj_xscacle(d.px2) - 2) + " " + (proj_yscacle(d.py2) - 2) + ") translate(" + (proj_xscacle(d.px2) - 16) + "," + (proj_yscacle(d.py2) - 16) + ")  scale(0.5) ")

                    loc.append("path")
                        .attr("class", "tbrm")
                        .attr("num", d.id)
                        .attr("fill", "steelblue")
                        .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                        .attr("transform", "rotate(" + (orr2) + " " + (loc_xscacle(d.lx2) - 2) + " " + (loc_yscacle(d.ly2) - 2) + ") translate(" + (loc_xscacle(d.lx2) - 16) + "," + (loc_yscacle(d.ly2) - 16) + ")  scale(0.5) ")
                    // .attr("transform", "rotate(180 64 62) translate(50 50) scale(0.5)")

                    idSel.push(d.id)

                    let tpath = proj.append("line")
                        .attr("class", "tbrm")
                        .attr("num", d.id)
                        .attr("x1", proj_xscacle(d.px1))
                        .attr("y1", proj_yscacle(d.py1))
                        .attr("x2", proj_xscacle(d.px2))
                        .attr("y2", proj_yscacle(d.py2))
                        .attr('stroke', 'steelblue')
                        .style('stroke-width', '3px');

                    let totalLength = tpath.node().getTotalLength();

                    tpath.attr("stroke-dasharray", totalLength + " " + totalLength)
                        .attr("stroke-dashoffset", totalLength)
                        .transition()
                        .duration(250)
                        .attr("stroke-dashoffset", 0);


                    let tpath2 = loc.append("line")
                        .attr("class", "tbrm")
                        .attr("num", d.id)
                        .attr("x1", loc_xscacle(d.lx1))
                        .attr("y1", loc_yscacle(d.ly1))
                        .attr("x2", loc_xscacle(d.lx2))
                        .attr("y2", loc_yscacle(d.ly2))
                        .attr('stroke', 'steelblue')
                        .style('stroke-width', '3px')

                    let totalLength2 = tpath2.node().getTotalLength();

                    tpath2.attr("stroke-dasharray", totalLength2 + " " + totalLength2)
                        .attr("stroke-dashoffset", totalLength2)
                        .transition()
                        .duration(250)
                        .attr("stroke-dashoffset", 0)

                }
            } else {
                let tid = idSel.indexOf(d.id);
                if (tid) {
                    idSel.splice(tid)
                    d3.selectAll('.tbrm[num="' + d.id + '"]').remove()
                }
            }
        })
    }


    loc2.on('mousemove', function () {
        const coords = d3.mouse(loc2.node());
        handleCirHovSyncLoc(cirhov4, coords, elements3, elements4, loc2, proj2);
    })


    proj2.on('mousemove', function () {
        const coords = d3.mouse(proj2.node());
        handleCirHovSyncProj(cirhov3, coords, elements3, elements4, loc2, proj2);
    })


    loc3.on('mousemove', function () {
        const coords = d3.mouse(loc3.node());
        handleCirHovSyncLoc(cirhov6, coords, elements5, elements6, loc3, proj3);
    })


    proj3.on('mousemove', function () {
        const coords = d3.mouse(proj3.node());
        handleCirHovSyncProj(cirhov5, coords, elements5, elements6, loc3, proj3);
    })


    loc.on('mousemove', function () {

        const coords = d3.mouse(loc.node());
        // console.log('Lalalaa');
        handleCirHovSyncLoc(cirhov2, coords, elements, elements2, loc, proj);

    });


</script>


</body>
</html>
