<!DOCTYPE html>
<html lang="en">
<head>

    <!-- Basic Page Needs
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <meta charset="utf-8">
    <title>Projection</title>
    <meta name="description" content="">
    <meta name="author" content="Theo Jaunet, Romain Vuillemot, and Christian Wolf">
    <script src="https://d3js.org/d3.v5.min.js"></script>
    <!-- Mobile Specific Metas
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- FONT
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

    <!-- CSS
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link rel="stylesheet" href="assets/css/normalize.css">
    <link rel="stylesheet" href="assets/css/skeleton.css">

    <!-- Favicon
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link rel="icon" type="image/png" href="assets/images/favicon/favicon.ico">
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"
            integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
    <script src="assets/js/projector.js"></script>
    <script src="assets/js/local.js"></script>
    <style>
        path {

            /*opacity: 0.8;*/
        }

        .play {
            border: none;
        }

        .play:hover {

            cursor: pointer;
            transform: scale(1.1);
        }


        .focus {

            cursor: pointer;
            text-decoration: underline;

        }

        input::-moz-focus-inner {
            border: 0;
        }

        input[type=range]::-moz-focus-outer {
            border: 0;
        }

        input[type="range"] {
            -webkit-appearance: none;
            -moz-apperance: none;
            border-radius: 6px;
            height: 6px;
            user-select: none;
            outline: none;
            width: 100%;
            border: 0;
            background-image: -webkit-gradient(
                    linear,
                    left top,
                    right top,
                    color-stop(0, #233E34),
                    color-stop(0, #C5C5C5)
            );
            -webkit-touch-callout: none; /* iOS Safari */
            -webkit-user-select: none; /* Safari */
            -khtml-user-select: none; /* Konqueror HTML */
            -moz-user-select: none; /* Firefox */
            -ms-user-select: none; /* Internet Explorer/Edge */
            user-select: none;
            user-focus: none;
            /* Non-prefixed version, currently
                                             supported by Chrome and Opera */
        }

        input[type='range']::-webkit-slider-thumb {
            -webkit-appearance: none !important;
            background-color: #183d4e;
            border: 1px solid #183d4e;
            height: 20px;
            width: 20px;
            border-radius: 50%;
            -webkit-touch-callout: none; /* iOS Safari */
            -webkit-user-select: none; /* Safari */
            -khtml-user-select: none; /* Konqueror HTML */
            -moz-user-select: none; /* Firefox */
            -ms-user-select: none; /* Internet Explorer/Edge */
            user-select: none;
            cursor: pointer;
        }

        input[type='range']::-moz-range-thumb {
            -webkit-appearance: none !important;
            background-color: #183d4e;
            border: 1px solid #183d4e;
            height: 18px;
            width: 18px;
            opacity: 1;
            border-radius: 50%;
            -webkit-touch-callout: none; /* iOS Safari */
            -webkit-user-select: none; /* Safari */
            -khtml-user-select: none; /* Konqueror HTML */
            -moz-user-select: none; /* Firefox */
            -ms-user-select: none; /* Internet Explorer/Edge */
            user-select: none;
            cursor: pointer;
        }

        img {

            border: #888888 solid 1px;
            margin: 2px;
        }

        .actcl:hover {
            cursor: pointer;
            /*border: #333333 solid 1px;*/
            /*background-color: #33d2ff;*/
            border-radius: 4px;

        }
    </style>

</head>
<body>

<!-- Primary Page Layout
–––––––––––––––––––––––––––––––––––––––––––––––––– -->
<div class="container" style="margin-bottom: 5%; width: 1100px;max-width: 1100px">
    <div class="row">
        <div class="twelve column" style="margin-top: 10%">
            <h4 style="text-align: center"><span style="text-decoration:line-through rgba(0,0,0,0.4) ">Geo</span> Theo
                Guesser </h4>
            <h5 style="font-size: 2.2rem;color: rgba(0,0,0,0.5);text-align: center">
                If you wake up in Theo’s apartment could you guess where you are?
            </h5>


            <!--            <h4 style="text-align: left"> Introduction </h4>-->

            <div style="font-style: italic;margin-top: 10%">
                On the map on the right, try to pinpoint the point from which the observed image (shown left) has been
                taken.
                To do so, click on the corresponding location and then drag the appearing circle to configure the
                orientation angle.
            </div>
        </div>
    </div>


    <div>

    </div>


    <!--</div>-->
    <div class="row" style="text-align: center">

        <div class="three columns" style="margin-top: 2%;">

            <img id="guessimg" width="256" src="">
<!--            <img id="saliencim" width="256" src="">-->
            <button id="guesser" class="button-primary" style="margin-left: 25px"> Guess</button>
            <div style="text-align: left;margin-top: 60px;margin-left: 15px">
                <p style="text-underline: #555555;text-decoration: underline"> Score </p>
                <ul>
                    <li># of Guesses: <span id="nguess"></span></li>
                    <li> Avg Dist: <span id="avgDist"></span></li>
                    <!--                    <li> Avg Orr:</li>-->
                </ul>
            </div>
        </div>
        <div class="nine columns" style="margin-top: 2%;display: inline-block">

            <svg id="theo-guess" style="width: 100%;height: 580px;border: #555555 solid 1px;cursor: crosshair"></svg>
        </div>


    </div>


    <div class="row">
        <div class="twelve column" style="margin-top: 10%">
            <p>
                The last years have witnessed the soaring of Machine Learning, which has provided disruptive performance
                gains in several fields. Apart from undeniable advances in methodology, these gains are often attributed
                to massive amounts of training data and computing power, which led to breakthroughs in speech
                recognition, computer vision and language processing. Extending these advances to robotics, planning and
                control has proven to be difficult, as these applications often require learning from interactions
                instead of static data. They also currently suffer from low sample efficiency, often requiring billions
                of interactions <a onclick="focusRef('ref1')" class="focus">[1]</a>, which makes learning in real-time
                from physical interactions
                with real robots
                intractable.
                <br/><br/>
                Simulation is a promising direction, which allows training to proceed significantly faster than physical
                time on fast modern hardware, easily distributing multiple simulated environments over a large number of
                cores and machines. However, neural networks trained in simulated environments generally perform poorly
                when deployed on real robots and environments, mainly to the “sim2real” gap, i.e. the lack of accuracy
                in simulating real environment conditions [X][X][X]. The exact nature of the gap is often difficult to
                pinpoint, and modelling this gap and a successful transfer from simulation to physical environments has
                become a major subfield between machine learning and robotics.
                <br/><br/>
                This work is at the crossroads of three different fields and explores techniques of data visualization
                to advance machine learning for robotics applications. We propose new techniques for the visualization
                of the sim2real gap, which provide insights into the difference in performance obtained when neural
                networks are applied out of distribution (OOD) in real settings. The objective is to pinpoint transfer
                problems and to assist researchers and engineers in the fields of machine learning for robotics to
                design neural models which better transfer to real world scenarios.
                <br/><br/>
                The concrete application we target is robot localization, also called ego-pose estimation, which
                requires to estimate the 3D position and viewpoint (2 angles) of a mobile robot navigating in a 3D
                environment, in our case an apartment. At each time step t, the robot
                observes two ego-centric images (an RGB image It and a depth image Dt) from an onboard camera, from
                which a convolutional neural network directly regresses the robot’s pose pt = f(It, Dt; θ), where θ are
                the network parameters obtained with supervised training in simulation. The pose is defined as pt = [xt,
                yt, ɑt, βt ], two coordinates and two angles.

                <br/><br/>

                <!--
                                But first, are you (as a human) able to solve this task?

                                <br/><br/>
                -->


            </p>
        </div>

    </div>


    <div class="row">
        <div class="twelve column" style="margin-top: 10%">
            <h4 style="text-align: left"> Let's see how a model performs </h4>
            <p>
                Inspired by PoseNet <a onclick="focusRef('ref4')" class="focus">[4]</a>, we designed and trained a
                convolutional deep learning model
                able to regress
                the coordinates and
                orientation of a given RGB (color) & depth image. This model contains five CNN layers used to process
                the given images and extract features from them. Those extracted features are then given to three fully
                connected layers which use these features to decide the location (x and y coordinates) and orientation
                angle.

            </p>
            <div style="position: relative;width: 100%;text-align: center;margin-bottom: 15%">

                <img src="assets/nn2.png" style="width: 750px; border: none">

                <span style="position: absolute;bottom: -6px;right: 270px" id="umapMarl"> Features for Umap</span>
                <p style="position: absolute;bottom: 59px;right: 70px;text-align: left;font-weight: 800;font-style: italic">
                    x = 12.6, <br> y = 3.84, <br> angle = 63.12<br>
                </p>

                <p style="position: absolute;top: 46px;left: 132px;text-align: left;font-weight: 800;font-style: italic;text-anchor: end">
                    RGB
                </p>

                <p style="position: absolute;top: 166px;left: 120px;text-align: left;font-weight: 800;font-style: italic;text-anchor: end">
                    Depth
                </p>
                <span style="position: absolute;bottom: -75px;border: #333333 solid 1px;            border-radius: 4px;"
                      class="actcl"> Click here for details on the model and it's training</span>

            </div>


            <p>
                In the figure below (right side), we show a
                trajectory starting in the living room, and ending in the laundry
                – click on the play button to see the full animation of observed RGB and
                depth images. Superimposed over the map image (below, right), we present the
                predicted poses estimated by the deep neural network, drawn as oriented arrows.
                The given trajectory is not part of the training set, the obtained error therefore
                shows the sim2sim generalization performance, indicating whether the model can
                perform well on unseen images in simulation.

                Hovering those arrows with the mouse
                will display the ground truth coordinates of those images and hence how wrong a prediction is. The color
                of each dot encodes the prediction error, i.e. distance to the ground truth colored between green (low
                error) to red, (high error).
            </p>
            <p>
                To the left, we provide a visualization of the feature representation used by the neural network in the
                form of the activations of its last CNN layer (indicated in the <a class="focus"
                                                                                   onclick="focusRef('umapMarl')">figure
                above</a>). We show a Umap projection
                of features extracted from
                nearly 12000 previously unseen
                images. The location of its dot represents the features of an image, and its color corresponds to the
                room this image
                has been taken from based on predicted coordinates (the mapping from locations to rooms has been
                determined manually). We can observe that the model is
                quite able to distinguish rooms, with the exception of some ambiguities at the intersection of clusters.
                We can
                conclude that the model properly learned to identify rooms, as long as we stay in the same simulated
                environment.
            </p>


        </div>

    </div>
    <div class="row">
        <div class="twelve columns" style="margin-top: 1%;position: relative;height: 130px">
            <div style="position: absolute;right: 48.1%;top:108%">
                <img src="" height="128" width="128" id="imgr" style="position: absolute">
                <img src="" height="128" width="128" id="depthr" style="position: absolute;left:140px; ">
                <img src="" height="128" width="128" id="salr" style="position: absolute;left:280px; ">
            </div>
            <!--            <img class="play" id="play1" style="width: 29px;position: absolute;left: 290px;top:40px"
                             src="assets/play-sign.svg">
                        <input id="timeline" type="range" min="0" max="57" step="1" value="0"
                               style="position: absolute;left: 335px;top:52px;width: 450px">
                        <p id="timelineTxt" style="position: absolute;left: 793px;top:43px"> 0 </p>-->

        </div>
    </div>
    <div class="row">

        <div class="six columns" style="margin-top: 1%">
            <!--            <svg id="proj" style="width: 100%;height: 530px;border: #555555 solid 1px"></svg>-->
            <svg id="allProj" style="width: 100%;height: 530px;border: #555555 solid 1px"></svg>
            <div style="text-align: center;color: rgba(0,0,0,0.5)">
                Umap projection of features 12000 images. Each dot represents an image classified by the model, and
                their color their estimated room derived from the model's predicted coordinates.
            </div>
        </div>
        <div class="six columns" style="margin-top: 1%">
            <svg id="loc" style="width: 100%;height: 370px;     border: none;margin-top: 160px"></svg>
            <div style="text-align: center;color: rgba(0,0,0,0.5)">
                Neural model's predictions of coordinates and orientation angles of given images sampled from a
                trajectory in the simulator. The color of each arrow encodes how wrong a prediction is from low error
                (green) to high error (red).
            </div>

        </div>
    </div>


    <!--    <div class="row">
            <div class="twelve column" style="margin-top: 2%">

                <p>
                    Overall, we can see on the Umap projection that despite some noise, the model learned in its features to
                    discretise images per rooms.
                <ul>
                    <li>
                        TODO: Full Umap of original model.
                    </li>
                </ul>


                </p>
            </div>
        </div>-->


    <div class="row">
        <div class="twelve column" style="margin-top: 10%">
            <h4 style="text-align: left"> Such a model is quite noise sensitive.. </h4>
            <p>

                Let us recall that the main objective of such a neural model is to deploy it to a real environment
                involving observations from a real physical robot. This will result in differences with respect to the
                simulated training environment, for instance, displaced, removed or additional objects, opened or
                closed doors, but also low level changes like different luminosity and lighting, different focal lengths
                and geometry of the camera and other disparities due to different physical conditions. Those differences
                called the reality-gap, may have a huge impact on the model's prediction despite not being particularly
                difficult for humans.
                As an illustration, the figure below shows two different observations
                from roughly the same orientation and coordinates. The images on the left side, provided by the
                simulator
                tend to be more yellowish and are shaded a bit differently. In addition, the
                real camera does not have the same focal length. The two depth sensor does not have the same dynamic
                range. This results in an important shift of values (light gray) which, if taken literally without
                adaptation, could can be
                interpreted as free navigational space ahead although obstacles are present in the scene.


            </p>
            <div style="display: inline-block;text-align: center;width: 100%">
            </div>
            <div style="position: relative;margin-top: 5%;text-decoration: #555555 underline">
                <p style="position: absolute;left: 20%;top:-50px;width: 100px;text-decoration: #555555 underline">
                    Simulator</p>
                <p style="position: absolute;right: 20%;top:-50px;;width: 100px;text-decoration: #555555 underline">
                    Real</p>
            </div>
            <div style="display: inline;text-align: center">
                <img src="datasets/temp/rgb31.jpg">
                <img src="datasets/temp/depth31.jpg">

                <div style="border-left:2px solid #c4c4c4; height: 256px; display: inline-block;margin-left: 10px;margin-right: 10px "></div>
                <img src="datasets/realSal/depth31.jpg">
                <img src="datasets/realSal/rgb31.jpg">
            </div>

            <div style="position: relative;width: 100%">
                <p style="position: absolute;left: 128px;bottom:-50px;width: 100px"> RGB</p>
                <p style="position: absolute;left: 363px;bottom:-50px;width: 100px"> Depth</p>

                <p style="position: absolute;right: 338px;bottom:-50px;width: 100px"> Depth</p>
                <p style="position: absolute;right: 72px;bottom:-50px;width: 100px"> RGB</p>
            </div>

            <p style="margin-top: 7%">

                To ease evaluation and visualization, in what follows, we approximate a real sim2real
                gap through a procedurally created difference. In the figure below, we simulate
                different disparities by applying different noises, which can be chosen interactively,
                on a simulated trajectory.

                Shown below we can observe the impact of these disparities on the model's prediction. On the left side,
                both simulated and "real" features are projected into the same parametric Umap space, i.e. dots
                locations in this projection share the same meaning. Swiching between trajectories, we can observe how
                some rooms are more
                affected than others by the gap. For instance, we can see that in trajectory [XX],
                the model ...

                Changing noises types, we see that [XX] makes the model fail most of its predictions. One
                hypothesis we came up with is that the model heavily relies on the depth channel for its decisions, t

                As we can see below, most of the model's predictions are far from where they were sampled, and
                some are not even predicted outside the building.
            </p>
        </div>
    </div>

    <div class="row">
        <div class="twelve columns" style="margin-top: 8%;position: relative;height: 130px">
            <div style="position: relative;margin-top: 2%;text-decoration: #555555 underline;text-align: center;margin-bottom: -10px">
                <p style="position: absolute;left:90px ;top:-50px;width: 100px;text-decoration: #555555 underline;text-anchor: middle">
                    Simulator</p>
                <p style="position: absolute;right: 90px;top:-50px;width: 100px;text-decoration: #555555 underline;text-anchor: middle">
                    Noise/Real</p>
            </div>
            <img src="" height="128" width="128" id="imgr2" style="position: absolute">
            <img src="" height="128" width="128" id="depthr2" style="position: absolute;left:130px; ">
            <img src="" height="128" width="128" id="imgb2" style="position: absolute;right: 0">
            <img src="" height="128" width="128" id="depthb2" style="position: absolute;right: 130px">


            <!--            <div style="position: absolute;left:470px; top: 65px">
                            <label for="trajsel2">Trajectory</label>
                            <select class="" id="trajsel2">
                                <option value="0">0</option>
                                <option value="1">1</option>
                                <option value="2">2</option>
                                <option value="3">3</option>
                                <option value="4">4</option>
                            </select>
                        </div>-->

            <div style="position: absolute;left:570px; top: 65px">
                <label for="noisel2">Noise</label>
                <select class="" id="noisel2">
                    <option value="gaussian">Gaussian</option>
                    <option value="edge">Edge-Enhancing</option>
                    <option value="brightness">Brightness</option>
                    <option value="pepper">Pepper</option>
                    <option value="sharpen">Sharpen</option>
                    <option value="trans">Transforms</option>
                    <option value="white">White balance</option>

                </select>
            </div>

            <!--
                        <img class="play" id="play2" style="width: 29px;position: absolute;left: 290px;top:40px"
                             src="assets/play-sign.svg">
                        <input id="timeline2" type="range" min="0" max="57" step="1" value="0"
                               style="position: absolute;left: 335px;top:52px;width: 450px">
                        <p id="timelineTxt2" style="position: absolute;left: 793px;top:43px"> 0 </p>-->
        </div>
    </div>


    <div class="row">
        <div class="six columns" style="margin-top: 3%">
            <svg id="proj2" style="width: 100%;height: 530px;border: #555555 solid 1px"></svg>
        </div>
        <div class="six columns" style="margin-top: 3%">
            <svg id="loc2" style="width: 100%;height: 370px;border: none;margin-top: 160px"></svg>
        </div>
        <div class="twelve columns" style="height: 140px" id="imband2"></div>
    </div>


    <div class="row">
        <div class="ten column" style="margin-top: 8%">
            <h4 style="text-align: left"> Domain Randomization to the rescue</h4>

            <p>
                A standard technique to tackle these an issues, is Domain Randomization <a onclick="focusRef('ref2')"
                                                                                           class="focus">[2]</a>.
                It consist in modifying high level parameters of the simulator in order to force the agent to adapt to
                those changes and thus learn invariant
                features. The changes in the simulator can take many forms, such as visual data augmentation (e.g.
                gaussian noise, lighting, textures, colors balance) or changes on the simulator itself (e.g. camera
                position, orientation or field of view). Those
                changes are applied during the training phase of the agent, and as we observe below this improves the
                performances of the neural model on unseen simulated images and "real" images.
            </p>

            <div class="row">
                <div class="twelve columns" style="margin-top: 8%;position: relative;height: 130px">
                    <div style="position: relative;margin-top: 2%;text-decoration: #555555 underline;text-align: center;margin-bottom: -10px">
                        <p style="position: absolute;left:90px ;top:-50px;width: 100px;text-decoration: #555555 underline;text-anchor: middle">
                            Simulator</p>
                        <p style="position: absolute;right: 90px;top:-50px;width: 100px;text-decoration: #555555 underline;text-anchor: middle">
                            Noise/Real</p>
                    </div>
                    <img src="" height="128" width="128" id="imgr3" style="position: absolute">
                    <img src="" height="128" width="128" id="depthr3" style="position: absolute;left:130px; ">
                    <img src="" height="128" width="128" id="imgb3" style="position: absolute;right: 0">
                    <img src="" height="128" width="128" id="depthb3" style="position: absolute;right: 130px">


                    <div style="position: absolute;left:470px; top: 65px">
                        <label for="trajsel3">Trajectory</label>
                        <select class="" id="trajsel3">
                            <option value="r">real</option>
                            <option value="0">0</option>
                            <option value="1">1</option>
                            <option value="2">2</option>
                            <option value="3">3</option>
                            <option value="4">4</option>
                        </select>
                    </div>

                    <div style="position: absolute;left:570px; top: 65px">
                        <label for="noisel3">Noise</label>
                        <select class="" id="noisel3">
                            <option value="gaussian">Gaussian</option>
                            <option value="edge">Edge-Enhancing</option>
                            <option value="brightness">Brightness</option>
                            <option value="pepper">Pepper</option>
                            <option value="sharpen">Sharpen</option>
                            <option value="trans">Transforms</option>
                            <option value="white">White balance</option>

                        </select>
                    </div>


                    <img class="play" id="play3" style="width: 29px;position: absolute;left: 290px;top:40px"
                         src="assets/play-sign.svg">
                    <input id="timeline3" type="range" min="0" max="57" step="1" value="0"
                           style="position: absolute;left: 335px;top:52px;width: 450px">
                    <p id="timelineTxt3" style="position: absolute;left: 793px;top:43px"> 0 </p>
                </div>
            </div>

        </div>
    </div>


    <div class="row">
        <div class="six columns" style="margin-top: 3%">
            <svg id="proj3" style="width: 100%;height: 530px;border: #555555 solid 1px"></svg>
        </div>
        <div class="six columns" style="margin-top: 3%;height: 100%;vertical-align: center">
            <svg id="loc3" style="width: 100%;height: 370px;     border: none;margin-top: 84px"></svg>
        </div>
        <div class="twelve columns" style="height: 140px" id="imband3"></div>
    </div>


    <!--    <div class="row" style="margin-top: 8%;position: relative;">

            <div class="six columns">
                <svg id="allProj2" style="width: 100%;height: 530px;border: #555555 solid 1px"></svg>
            </div>

            <div class="six columns">

                <p>
                    Hello There
                </p>

            </div>

        </div>-->


    <div class="row">
        <div class="twelve column" style="margin-top: 8%">
            <!--            <h4 style="text-align: left"> Using real-images</h4>-->
            <!-- <p>
                 Using backprogation of predictions, one can extract the gradient and build saliency maps which depicts
                 the most influencial parts of the inputed image.

                 <br> <br><br>
                 &#45;&#45; Some furniture have more impact than others, e.g. couch
                 <br>

                 &#45;&#45; Mistake despite having a painting on focus in saliency map. Did it mistaken that for another item ?
                 <br>
                 &#45;&#45; Focus on Brooms in laundry.

             </p>


             <p>
                 &#45;&#45; Fix the gap in depth with a manual function.

                 &#45;&#45; Use color shifts to make the rgb look alike

             </p>


             <div style="width: 100%;text-align: center;position: relative">
                 <svg id="saliency" style="width: 60%;height: 580px">
                     <path id="guess" num="0" tx="734.5" ty="262" ox="709.5" oy="258" thor="-78.51800864525191" tr="0"
                           fill="steelblue" d="m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23"
                           transform="translate(544.8447704990486, 220.30411052580246) rotate(-78.51800537109375) scale(1.2999999523162842,1.2999999523162842)"
                           style="stroke: rgba(0, 0, 0, 0.6); stroke-width: 2px;"></path>
                     <path id="guess" num="0" tx="260.5" ty="321" ox="272.5" oy="325" thor="26.56505117707799" tr="0"
                           fill="steelblue" d="m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23"
                           transform="translate(192.87244703777895, 230.11733937741064) rotate(26.565052032470707) scale(1.2999999523162842,1.2999999523162842)"
                           style="stroke: rgba(0, 0, 0, 0.6); stroke-width: 2px;"></path>
                 </svg>


                 <div style="position: absolute;background-image: url('datasets/realSal/rgb0.jpg');top: 10px;right: -45px;height: 256px ">
                     <img src="datasets/realSal/sal0.jpg" style="opacity: 0.6"/>
                 </div>

                 <div style="position: absolute;background-image: url('datasets/realSal/rgb0.jpg');top: 10px;right: -45px;height: 256px ">
                     <img src="datasets/realSal/sal0.jpg" style="opacity: 0.6"/>
                 </div>

                 <div style="position: absolute;background-image: url('datasets/realSal/rgb0.jpg');top: 10px;right: -45px;height: 256px ">
                     <img src="datasets/realSal/sal0.jpg" style="opacity: 0.6"/>
                 </div>

             </div>


             <div>

                 <img src="datasets/realSal/rgb31.jpg"/>
                 &lt;!&ndash;                        <img src="datasets/temp/rgb0.jpg"/>&ndash;&gt;
                 <img src="datasets/temp/rgb31.jpg"/>

                 <div style="border-left:2px solid #c4c4c4; height: 256px; display: inline-block;margin-left: 10px;margin-right: 10px "></div>

                 <img src="datasets/realSal/rgb0.jpg"/>
             </div>
             <div>
                 <img src="datasets/realSal/sal31.jpg"/>
                 <img src="datasets/temp/sal31.jpg"/>
                 <div style="border-left:2px solid #c4c4c4; height: 256px; display: inline-block;margin-left: 10px;margin-right: 10px "></div>

                 <img src="datasets/realSal/sal0.jpg"/>

             </div>
 -->
            <!--      </div>
              </div>
          -->

            <!--
                <div class="row">
                    <div class="twelve column" style="margin-top: 8%">
                        <h4 style="text-align: left"> Do it yourself!</h4>
                        <p>
                        </p>

                        <ul>
                            <li>
                                Speak of domain adaptation
                            </li>
                            <li>

                            </li>
                        </ul>
                    </div>
                </div>
            -->


            <div class="row" style="text-align: center">
                <div class="twelve columns" style="margin-top: 2%;display: inline-block">
                    <div style=" text-align: left;margin-bottom: 50px">
                        <h5>Authors</h5>
                        <p><a href="https://theo-jaunet.github.io/">Théo Jaunet</a> (<a
                                href="https://twitter.com/jaunet_theo">@jaunet_theo</a>),
                            <a href="http://romain.vuillemot.net/">Romain
                                Vuillemot</a> (<a href="https://twitter.com/romsson">@romsson</a>) and <a
                                    href="https://perso.liris.cnrs.fr/christian.wolf/">Christian Wolf </a>(<a
                                    href="https://twitter.com/chriswolfvision">@chriswolfvision</a>), at LIRIS lab Lyon
                            -
                            France.
                        </p>
                        This work takes place in Théo jaunet's Ph.D. which is supported by a French Ministry Fellowship
                        and the
                        <a
                                href="https://projet.liris.cnrs.fr/mi2/"> M2I project</a>,
                    </div>

                </div>
            </div>


            <div class="row">
                <h4>Citations</h4>
            </div>
            <div class="row">
                <div class="ten columns">
                    <ol>
                        <li style="color: rgba(0,0,0,0.9);" id="ref1">
                            Deep Reinforcement Learning on a Budget: 3D Control and Reasoning Without a Supercomputer
                            [<a
                                href="https://arxiv.org/abs/1904.01806">URL</a>].
                            <div style="color: rgba(0,0,0,0.5);margin-left: 15px">
                                Edward Beeching, Christian Wolf, Jilles Dibangoye and Olivier Simonin<br>
                                International Conference on Pattern Recognition (ICPR), 2020<br>
                            </div>
                        </li>

                        <li style="color: rgba(0,0,0,0.9);" id="ref2">
                            Domain
                            randomization for transferring deep neural networks from simulation to the real world [<a
                                href="https://arxiv.org/abs/1703.06907">URL</a>]
                            <div style="color: rgba(0,0,0,0.5);margin-left: 15px">
                                Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, Pieter Abbeel
                                <br/>
                                IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2017
                            </div>
                        </li>


                        <li style="color: rgba(0,0,0,0.9);" id="ref3">
                            Habitat: A Platform for Embodied AI Research [<a
                                href="https://arxiv.org/abs/1904.01201">URL</a>]
                            <div style="color: rgba(0,0,0,0.5);margin-left: 15px">
                                Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans,
                                Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra Malik, Devi Parikh, Dhruv
                                Batra
                                <br/>
                                Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2019
                            </div>
                        </li>

                        <li style="color: rgba(0,0,0,0.9);" id="ref4">
                            Posenet: A convolutional network for real-time 6-dof camera relocalization [<a
                                href="https://arxiv.org/abs/1505.07427">URL</a>]
                            <div style="color: rgba(0,0,0,0.5);margin-left: 15px">
                                Alex Kendall, Matthew Grimes, and Roberto Cipolla <br/>
                                Proceedings of the IEEE international conference on computer vision (ICCV), 2015
                            </div>
                        </li>


                    </ol>
                </div>

            </div>
        </div>


        <script>
            // const data = fakedata(200);
            let dato;
            let dat;
            let dato2;
            let dato3;

            let hacl = false;

            let tref;

            let dator;
            let idSel = [];

            let elements;
            let elements2;

            let elements3;
            let elements4;

            let elements5;
            let elements6;

            let curStep0 = 0;

            let curStep = 0;
            let curTraj = "0";
            let curNoise = "gaussian";


            let curStep2 = 0;
            let curTraj2 = "0";
            let curNoise2 = "gaussian";

            let pl = false;
            let timer = null;
            let timer2 = null;
            let timer3 = null;

            let rotSt = false;
            let guessid;

            let nguess = 0
            let avgDist = 0
            let avgOrr = 0


            let guessw = true

            const proj = d3.select("#proj");
            const loc = d3.select("#loc");

            const proj2 = d3.select("#proj2");
            const loc2 = d3.select("#loc2");


            const proj3 = d3.select("#proj3");
            const loc3 = d3.select("#loc3");

            let p1 = [[-5.994728088378906, 16.698274612426758], [-4.038941860198975, 14.940378189086914]];
            let proj_xscacle = d3.scaleLinear().domain(p1[0]).range([20, 515]); // Scale to Change based on SVG Size
            let proj_yscacle = d3.scaleLinear().domain(p1[1]).range([20, 515]);

            let colscale = d3.scaleLinear().domain([0, 20]).range(['green', 'red']);
            let colscaleizy = d3.scaleLinear().domain([0, 60]).range(['green', 'red']);
            let tsvg = d3.select("#theo-guess");


            function focusRef(id) {
                console.log(id);
                document.getElementById(id).scrollIntoView({block: 'center', behavior: 'smooth'})
            }


            function handleAcl() {

                hacl = !hacl
            }


            $("#guesser").on("click", function () {

                if (rotSt) {

                    d3.select("#guessLine").remove();
                    d3.select("#guessCr").remove();


                    let txscale = d3.scaleLinear(simW, [50, 750])
                    let tyscale = d3.scaleLinear(simH, [25, 545])
                    // const coords = d3.mouse(tsvg.node());


                    let pred_tx = txscale(tref[guessid].lx1);
                    let pred_ty = tyscale(tref[guessid].lx2);
                    let pred_torr = tref[guessid].lorr1;


                    let tx = txscale(tref[guessid].tx);
                    let ty = tyscale(tref[guessid].ty);
                    let torr = tref[guessid].torr;


                    nguess += 1;

                    let el = $("#guess");

                    $("#guesser").html("Try again!")
                    $("#nguess").html(nguess);

                    avgDist += euclidian_dist([tx, ty], [el.attr("ox"), el.attr("oy")]);
                    $("#avgDist").html(Math.round(avgDist / nguess));


                    tsvg.append("path")
                        .attr("id", "gtpath")
                        .attr("fill", "green")
                        .style("stroke", "rgba(0,0,0,0.6)")
                        .style("stroke-width", "2px")
                        .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                        .attr("transform", d => {
                                return "rotate(" + (180 - torr) + " " + (tx - 6) + " " + (ty - 6) + ") translate(" + (tx - 32) + "," + (ty - 32) + ") scale(1.5)"
                            }
                        );


                    tsvg.append("path")
                        // .attr("id", "gtpath")
                        .attr("fill", "purple")
                        .style("stroke", "rgba(0,0,0,0.6)")
                        .style("stroke-width", "2px")
                        .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                        .attr("transform", d => {
                                return "rotate(" + (180 - pred_torr) + " " + (pred_tx - 6) + " " + (pred_ty - 6) + ") translate(" + (pred_tx - 32) + "," + (pred_ty - 32) + ") scale(1.5)"
                            }
                        );


                    // tsvg.append("line")
                    //     .attr("x1", tx - 5)
                    //     .attr("x2", el.attr("ox") - 5)
                    //     .attr("y2", el.attr("oy") - 5)
                    //     .attr("y1", ty - 5)
                    //     .attr("stroke", "#333333")
                    //     .attr("stroke-width", "2")
                    //     .attr("stroke-dasharray", "6,2")

                    /*     d3.select("#guess").transition().duration(100).style("fill", "#333333")
                             .attr("id", "")*/
                    rotSt = false;
                } else {


                    const introsvg = d3.select("#theo-guess")


                    introsvg.selectAll("path").remove()
                    introsvg.selectAll("line").remove()

                    // guessid = getRandomInt(0, tref.length - 1);
                    guessid = getRandomInt(0, tref.length - 1);

                    $("#guessimg").attr("src", "data:image/jpeg;base64," + tref[guessid].imgR);
                    $("#saliencim").attr("src", "data:image/jpeg;base64," + tref[guessid].salR);

                    $("#guesser").html("Guess")

                }


            });


            tsvg.on("click", function (e) {

                if (!rotSt) {
                    // console.log(e);0
                    rotSt = true;
                    const coords = d3.mouse(tsvg.node());

                    //
                    // tsvg.append("circle")
                    //     .attr("id", "guess")
                    //     .attr("cx", coords[0])
                    //     .attr("cy", coords[1])
                    //     .attr("ty", coords[1])
                    //     .attr("tx", coords[0])
                    //     .attr("r", "5")
                    //     .attr("fill", "steelblue")


                    tsvg.append("line")
                        .attr("id", "guessLine")
                        .attr("x1", coords[0] + 3)
                        .attr("x2", coords[0] + 3)
                        .attr("y1", coords[1] - 8)
                        .attr("y2", coords[1] + 40)
                        .attr("stroke", 'red')
                        .attr("stroke-width", "3")
                        .attr("stroke-dasharray", "6,2");


                    tsvg.append("path")
                        .attr("id", "guess")
                        .attr("num", 0)
                        .attr("tx", coords[0])
                        .attr("ty", coords[1])
                        .attr("ox", coords[0])
                        .attr("oy", coords[1])
                        .attr("thor", 0)
                        .attr("tr", 0)
                        .style("stroke", "rgba(0,0,0,0.6)")
                        .style("stroke-width", "2px")
                        .style("cursor", "grab")
                        .attr("fill", "steelblue")
                        .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                        .attr("transform", "rotate(" + (0) + " " + (coords[0] - 2) + " " + (coords[1] - 2) + ") translate(" + (coords[0] - 31) + "," + (coords[1] - 37) + ")  scale(1.3)")
                        .call(d3.drag()
                            .on("start", dragstarted)
                            .on("drag", dragged)
                            .on("end", dragended));


                    tsvg.append("circle")
                        .attr("id", "guessCr")
                        .attr("cx", coords[0] + 3)
                        .attr("cy", coords[1] + 40)
                        .attr("r", 6)
                        .style("cursor", "grab")
                        .attr("fill", "steelblue")

                        .call(d3.drag()
                            .on("start", dragstarted2)
                            .on("drag", dragged2)
                            .on("end", dragended2));

                    /*            .attr("stroke", 'red')
                            .attr("stroke-width", "3")
                            .attr("stroke-dasharray", "6,2")*/

                }
            });


            function dragstarted(d) {
                d3.select(this).raise().attr("stroke", "black");
            }

            function dragged(d) {
                const point = d3.mouse(tsvg.node());

                let path = d3.select("#guess");
                let line = d3.select("#guessLine");
                let circle = d3.select("#guessCr");

                // console.log(point);


                let deltax = parseFloat(point[0] - path.attr("ox"));
                let deltay = parseFloat(point[1] - path.attr("oy"));

                path.attr("ox", point[0]);
                path.attr("oy", point[1]);

                path.transition().duration(15).attr("transform", "rotate(" + (path.attr("thor")) + " " + (point[0] - 6) + " " + (point[1] - 6) + ") translate(" + (point[0] - 32) + "," + (point[1] - 32) + ") scale(1.3) ")

                circle.attr("cx", parseFloat(circle.attr("cx")) + deltax);
                circle.attr("cy", parseFloat(circle.attr("cy")) + deltay);


                line.transition().duration(15).attr("x2", parseFloat(circle.attr("cx")) + deltax).attr("y2", parseFloat(circle.attr("cy")) + deltay).attr("x1", point[0] - 5).attr("y1", point[1] - 8)
                // if ((point[0] > 0 && point[0] < 340) && (point[1] > 0 && point[1] < 340))
                //     circle.attr("cx", point[0]).attr("cy", point[1]);
            }

            function dragended(d) {
                d3.select(this).attr("stroke", null);
            }


            function dragstarted2(d) {
                d3.select(this).raise().attr("stroke", "black");
            }

            function dragged2(d) {
                const point = d3.mouse(tsvg.node());

                let path = d3.select("#guess");
                let line = d3.select("#guessLine");
                let circle = d3.select("#guessCr");

                console.log(point);


                // let deltax = parseFloat(point[0] - path.attr("ox"));
                // let deltay = parseFloat(point[1] - path.attr("oy"));

                //
                // path.attr("ox", point[0])
                // path.attr("oy", point[1])


                const orr = -90 + (Math.atan2(point[1] - path.attr("oy"), (point[0] - path.attr("ox"))) * (180 / Math.PI));

                path.attr("thor", orr)

                path.transition().duration(15).attr("transform", "rotate(" + (orr) + " " + (path.attr("ox") - 1) + " " + (path.attr("oy") - 6) + ") translate(" + (path.attr("ox") - 36) + "," + (path.attr("oy") - 31) + ") scale(1.3)  ")
                circle.transition().duration(15).attr("cx", parseFloat(point[0])).attr("cy", parseFloat(point[1]));
                line.transition().duration(15).attr("x2", parseFloat(point[0])).attr("y2", parseFloat(point[1]));
                // circle.transition().duration(15)

                // if ((point[0] > 0 && point[0] < 340) && (point[1] > 0 && point[1] < 340))
                //     circle.attr("cx", point[0]).attr("cy", point[1]);
            }

            function dragended2(d) {
                d3.select(this).attr("stroke", null);
            }


            loadmap(d3.select("#theo-guess"), 'assets/images/map.jpg');
            loadmap(d3.select("#saliency"), 'assets/images/map.jpg');
            loadmap(d3.select("#loc2"), 'assets/images/map.jpg');
            loadmap(d3.select("#loc3"), 'assets/images/map.jpg');

            $("#timeline").on("input", function () {

                let step = $(this).val();
                let ell = dato[step];
                curStep0 = parseInt(step);

                $("#imgr").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
                $("#depthr").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

                $("#imgb").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
                $("#depthb").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

                $("#timelineTxt").html(step)

                update_time();

                let inside = d3.selectAll("path")

                inside.filter(d => {
                    return d.id > curStep0
                }).transition().duration(20).style("opacity", '0.1');


                inside.filter(d => {
                    return d.id <= curStep0
                }).transition().duration(20).style("opacity", '1')

            });


            $("#timeline2").on("input", function () {

                let step = $(this).val();
                let ell = dato2[step];
                curStep = parseInt(step);

                $("#imgr2").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
                $("#depthr2").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

                $("#imgb2").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
                $("#depthb2").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

                $("#timelineTxt2").html(step2)

                update_time2();

                let inside = d3.selectAll("path")

                inside.filter(d => {
                    return d.id > curStep
                }).transition().duration(20).style("opacity", '0.1');


                inside.filter(d => {
                    return d.id <= curStep
                }).transition().duration(20).style("opacity", '1')

            });


            $("#timeline3").on("input", function () {

                let step = $(this).val();
                let ell = dato3[step];
                curStep2 = parseInt(step);

                $("#imgr3").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
                $("#depthr3").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

                $("#imgb3").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
                $("#depthb3").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

                $("#timelineTxt3").html(step3)

                update_time3();

                let inside = d3.selectAll("path")

                inside.filter(d => {
                    return d.id > curStep2
                }).transition().duration(20).style("opacity", '0.1');


                inside.filter(d => {
                    return d.id <= curStep2
                }).transition().duration(20).style("opacity", '1')

            });


            $('#play1').on('click', function () {

                pl = !pl;
                if (pl) {
                    if (curStep0 >= dato.length)
                        curStep0 = 0
                    $(this).attr('src', 'assets/round-pause-button.svg');

                    timer = setInterval(step, 115);
                    step()
                } else {
                    $(this).attr('src', 'assets/play-sign.svg');
                    clearInterval(timer);
                    timer = null
                }
            });


            $('#play2').on('click', function () {

                pl = !pl;
                if (pl) {
                    if (curStep >= dato2.length)
                        curStep = 0
                    $(this).attr('src', 'assets/round-pause-button.svg');

                    timer2 = setInterval(step2, 115);
                    step2()
                } else {
                    $(this).attr('src', 'assets/play-sign.svg');
                    clearInterval(timer2);
                    timer2 = null
                }
            });


            $('#play3').on('click', function () {

                pl = !pl;
                if (pl) {
                    if (curStep2 >= dato3.length)
                        curStep2 = 0
                    $(this).attr('src', 'assets/round-pause-button.svg');

                    timer3 = setInterval(step3, 115);
                    step3()
                } else {
                    $(this).attr('src', 'assets/play-sign.svg');
                    clearInterval(timer3);
                    timer3 = null
                }
            });


            function update_time() {

                let tbar = $('#timeline');

                let val = (tbar.val() - tbar.attr('min')) / (tbar.attr('max') - tbar.attr('min'));

                tbar.css('background-image',
                    '-webkit-gradient(linear, left top, right top, '
                    + 'color-stop(' + val + ', #233E34), '
                    + 'color-stop(' + val + ', #C5C5C5)'
                    + ')'
                );
            }


            function update_time2() {

                let tbar = $('#timeline2');

                let val = (tbar.val() - tbar.attr('min')) / (tbar.attr('max') - tbar.attr('min'));

                tbar.css('background-image',
                    '-webkit-gradient(linear, left top, right top, '
                    + 'color-stop(' + val + ', #233E34), '
                    + 'color-stop(' + val + ', #C5C5C5)'
                    + ')'
                );
            }

            function update_time3() {

                let tbar = $('#timeline3');

                let val = (tbar.val() - tbar.attr('min')) / (tbar.attr('max') - tbar.attr('min'));

                tbar.css('background-image',
                    '-webkit-gradient(linear, left top, right top, '
                    + 'color-stop(' + val + ', #233E34), '
                    + 'color-stop(' + val + ', #C5C5C5)'
                    + ')'
                );
            }


            function step2() {

                curStep += 1;
                let ell = dato2[curStep];


                if (ell) {
                    $("#imgr2").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
                    $("#depthr2").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

                    $("#imgb2").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
                    $("#depthb2").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

                    $("#timelineTxt2").html(curStep)

                    $("#timeline2").val(curStep);

                    update_time2()


                    let inside = d3.selectAll("path")


                    inside.filter(d => {
                        return d.id > curStep
                    }).transition().duration(20).style("opacity", '0.1')


                    inside.filter(d => {
                        return d.id <= curStep
                    }).transition().duration(20).style("opacity", '1')

                } else {
                    pl = false;
                    $('#play2 ').attr('src', 'assets/play-sign.svg');
                    curStep = 0;
                    clearInterval(timer2);
                    timer2 = null
                }

            }


            function step3() {

                curStep2 += 1;
                let ell = dato3[curStep2];


                if (ell) {
                    $("#imgr3").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
                    $("#depthr3").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

                    $("#imgb3").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
                    $("#depthb3").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

                    $("#timelineTxt3").html(curStep2)

                    $("#timeline3").val(curStep2);

                    update_time3()


                    let inside = d3.selectAll("path")


                    inside.filter(d => {
                        return d.id > curStep2
                    }).transition().duration(20).style("opacity", '0.1')


                    inside.filter(d => {
                        return d.id <= curStep2
                    }).transition().duration(20).style("opacity", '1')

                } else {
                    pl = false;
                    $('#play3 ').attr('src', 'assets/play-sign.svg');
                    curStep2 = 0;
                    clearInterval(timer3);
                    timer3 = null
                }

            }


            function step() {

                curStep0 += 1;
                let ell = dato[curStep0];


                if (ell) {
                    $("#imgr").attr("src", 'data:image/jpeg;base64,' + ell.imgR)
                    $("#depthr").attr("src", 'data:image/jpeg;base64,' + ell.depthR)

                    $("#imgb2").attr("src", 'data:image/jpeg;base64,' + ell.imgB)
                    $("#depthb2").attr("src", 'data:image/jpeg;base64,' + ell.depthB)

                    $("#timelineTxt").html(curStep0)

                    $("#timeline").val(curStep0);

                    update_time()


                    let inside = d3.selectAll("path")


                    inside.filter(d => {
                        return d.id > curStep0
                    }).transition().duration(20).style("opacity", '0.1')


                    inside.filter(d => {
                        return d.id <= curStep0
                    }).transition().duration(20).style("opacity", '1')

                } else {
                    pl = false;
                    $('#play1').attr('src', 'assets/play-sign.svg');
                    curStep0 = 0;
                    clearInterval(timer);
                    timer = null
                }

            }


            const cirhov = proj.append("circle")
                .attr("id", "projHov")
                .attr("stroke", "#333333")
                .attr("stroke-width", "1")
                .attr("fill", "none")
                .attr("r", "24");

            const cirhov2 = loc.append("circle")
                .attr("id", "locHov")
                .attr("stroke", "#333333")
                .attr("stroke-width", "1")
                .attr("fill", "none")
                .attr("r", "24");


            const cirhov3 = proj2.append("circle")
                .attr("id", "locHov")
                .attr("stroke", "#333333")
                .attr("stroke-width", "1")
                .attr("fill", "none")
                .attr("r", "24");

            const cirhov4 = loc2.append("circle")
                .attr("id", "locHov")
                .attr("stroke", "#333333")
                .attr("stroke-width", "1")
                .attr("fill", "none")
                .attr("r", "24");

            const cirhov5 = proj3.append("circle")
                .attr("id", "locHov")
                .attr("stroke", "#333333")
                .attr("stroke-width", "1")
                .attr("fill", "none")
                .attr("r", "24");

            const cirhov6 = loc3.append("circle")
                .attr("id", "locHov")
                .attr("stroke", "#333333")
                .attr("stroke-width", "1")
                .attr("fill", "none")
                .attr("r", "24");


            $("#trajsel2").on("change", function () {

                curTraj = $("#trajsel2").val();

                getData1("datasets/bad/try" + "_" + curNoise + ".json").then(function () {

                    proj2.selectAll("path").remove();
                    proj2.selectAll("line").remove();
                    loc2.selectAll("path").remove();
                    loc2.selectAll("line").remove();

                    dato2.sort((a, b) => {

                        if (a.id > b.id) {
                            return 1
                        } else {
                            return -1
                        }

                    });


                    let elem = dato2.filter(d => d.id === 0)[0];


                    $("#imgr2").attr("src", 'data:image/jpeg;base64,' + elem.imgR)
                    $("#depthr2").attr("src", 'data:image/jpeg;base64,' + elem.depthR)

                    $("#imgb2").attr("src", 'data:image/jpeg;base64,' + elem.imgB)
                    $("#depthb2").attr("src", 'data:image/jpeg;base64,' + elem.depthB)


                    drawPoints(dato2, proj2);
                    drawElements(dato2, loc2);

                    elements3 = proj2.selectAll(".projDot");
                    elements4 = loc2.selectAll(".locDot");

                    $("#timeline2").attr("max", dato2.length - 1)
                });

            })


            $("#trajsel3").on("change", function () {


                    curTraj2 = $("#trajsel3").val();


                    if (curTraj2 !== "r") {
                        // getData2("datasets/traj" + curTraj2 + "/" + curTraj2 + "_" + curNoise2 + ".json").then(function () {
                        getData2("datasets/good/try2" + "_" + curNoise2 + ".json").then(function () {

                            proj3.selectAll("path").remove();
                            proj3.selectAll("line").remove();
                            loc3.selectAll("path").remove();
                            loc3.selectAll("line").remove();

                            dato3.sort((a, b) => {

                                if (a.id > b.id) {
                                    return 1
                                } else {
                                    return -1
                                }

                            });

                            let elem = dato3.filter(d => d.id === 0)[0];

                            // console.log(elem);

                            $("#imgr3").attr("src", 'data:image/jpeg;base64,' + elem.imgR)
                            $("#depthr3").attr("src", 'data:image/jpeg;base64,' + elem.depthR)

                            $("#imgb3").attr("src", 'data:image/jpeg;base64,' + elem.imgB)
                            $("#depthb3").attr("src", 'data:image/jpeg;base64,' + elem.depthB)


                            drawPoints(dato3, proj3);
                            drawElements(dato3, loc3);

                            elements5 = proj3.selectAll(".projDot");
                            elements6 = loc3.selectAll(".locDot");

                            $("#timeline3").attr("max", dato3.length - 1)
                        });
                    } else {


                        getData2("datasets/cbon.json").then(function () {

                            proj3.selectAll("path").remove();
                            proj3.selectAll("line").remove();
                            loc3.selectAll("path").remove();
                            loc3.selectAll("line").remove();

                            dato3.sort((a, b) => {

                                if (a.id > b.id) {
                                    return 1
                                } else {
                                    return -1
                                }

                            });

                            let elem = dato3.filter(d => d.id === 0)[0];
                            let telem = tref.filter(d => d.id === 0)[0];

                            // console.log(elem);

                            $("#imgr3").attr("src", 'data:image/jpeg;base64,' + telem.imgR)
                            $("#depthr3").attr("src", 'data:image/jpeg;base64,' + telem.depthR)

                            $("#imgb3").attr("src", 'data:image/jpeg;base64,' + elem.imgR)
                            $("#depthb3").attr("src", 'data:image/jpeg;base64,' + elem.depthR)


                            drawPoints(dato3, proj3);
                            drawElements(dato3, loc3);

                            elements5 = proj3.selectAll(".projDot");
                            elements6 = loc3.selectAll(".locDot");

                            $("#timeline3").attr("max", dato3.length - 1)
                        });

                    }
                }
            )


            $("#noisel2").on("change", function () {

                // console.log($("#trajsel").val());

                curNoise = $("#noisel2").val();

                getData1("datasets/bad/try" + "_" + curNoise + ".json").then(function () {


                    proj2.selectAll("path").remove();
                    proj2.selectAll("line").remove();
                    loc2.selectAll("path").remove();
                    loc2.selectAll("line").remove();

                    dato2.sort((a, b) => {

                        if (a.id > b.id) {
                            return 1
                        } else {
                            return -1
                        }

                    });


                    let elem = dato2.filter(d => d.id === 0)[0];


                    $("#imgr2").attr("src", 'data:image/jpeg;base64,' + elem.imgR);
                    $("#depthr2").attr("src", 'data:image/jpeg;base64,' + elem.depthR);

                    $("#imgb2").attr("src", 'data:image/jpeg;base64,' + elem.imgB);
                    $("#depthb2").attr("src", 'data:image/jpeg;base64,' + elem.depthB);


                    drawPoints(dato2, proj2);
                    drawElements(dato2, loc2);

                    elements3 = proj2.selectAll(".projDot");
                    elements4 = loc2.selectAll(".locDot");
                    $("#timeline2").attr("max", dato2.length - 1)

                });
            })


            $("#noisel3").on("change", function () {

                // console.log($("#trajsel").val());

                curNoise2 = $("#noisel3").val();

                // getData2("datasets/traj" + curTraj2 + "/" + curTraj2 + "_" + curNoise2 + ".json").then(function () {
                getData2("datasets/good/try2" + "_" + curNoise2 + ".json").then(function () {

                    proj3.selectAll("path").remove();
                    proj3.selectAll("line").remove();
                    loc3.selectAll("path").remove();
                    loc3.selectAll("line").remove();

                    dato3.sort((a, b) => {

                        if (a.id > b.id) {
                            return 1
                        } else {
                            return -1
                        }

                    });


                    let elem = dato3.filter(d => d.id === 0)[0];


                    console.log(elem);

                    $("#imgr3").attr("src", 'data:image/jpeg;base64,' + elem.imgR);
                    $("#depthr3").attr("src", 'data:image/jpeg;base64,' + elem.depthR);

                    $("#imgb3").attr("src", 'data:image/jpeg;base64,' + elem.imgB);
                    $("#depthb3").attr("src", 'data:image/jpeg;base64,' + elem.depthB);


                    drawPoints(dato3, proj3);
                    drawElements(dato3, loc3);

                    elements5 = proj3.selectAll(".projDot");
                    elements6 = loc3.selectAll(".locDot");
                    $("#timeline3").attr("max", dato3.length - 1)

                });
            })


            function getRandomInt(min, max) {
                min = Math.ceil(min);
                max = Math.floor(max);
                return Math.floor(Math.random() * (max - min + 1)) + min;
            }


            getRef("datasets/bad/try_gaussian.json").then(function () {
                // console.log(dat);

                guessid = getRandomInt(0, tref.length - 1)
                $("#guessimg").attr("src", "data:image/jpeg;base64," + tref[guessid].imgR);
                $("#saliencim").attr("src", "data:image/jpeg;base64," + tref[guessid].salR);
            })

            /*    getDatatry("datasets/try_gaussian.json").then(function () {


                    tsvg

                    console.log(dat);

                })*/

            // getData0("datasets/traj" + curTraj + "/" + curTraj + "_" + curNoise + ".json").then(function () {
            getData0("datasets/bad/try_gaussian.json").then(function () {

                /*
                        proj2.selectAll("path").remove();
                        proj2.selectAll("line").remove();
                        loc2.selectAll("path").remove();
                        loc2.selectAll("line").remove();


                        proj3.selectAll("path").remove();
                        proj3.selectAll("line").remove();
                        loc3.selectAll("path").remove();
                        loc3.selectAll("line").remove();*/


                guessid = getRandomInt(0, tref.length - 1)
                $("#guessimg").attr("src", "data:image/jpeg;base64," + tref[guessid].imgR)


                $("#timeline").attr("max", dato.length)
                dato.sort((a, b) => {

                    if (a.id > b.id) {
                        return 1
                    } else {
                        return -1
                    }
                });

                let elem = dato.filter(d => d.id === 0)[0];

                console.log(elem);

                $("#imgr").attr("src", 'data:image/jpeg;base64,' + elem.imgR)
                $("#depthr").attr("src", 'data:image/jpeg;base64,' + elem.depthR)
                $("#salr").attr("src", 'data:image/jpeg;base64,' + elem.salR)

                // $("#imgb").attr("src", 'data:image/jpeg;base64,' + elem.imgB)
                // $("#depthb").attr("src", 'data:image/jpeg;base64,' + elem.depthB)


                drawPoints(dato, proj);
                drawElementsBad(dato, loc);

                elements = loc.selectAll(".locDot");
                elements2 = loc.selectAll(".locDot");


            });


            getData1("datasets/bad/try" + "_" + curNoise + ".json").then(function () {

                $("#timeline2").attr("max", dato2.length)
                dato2.sort((a, b) => {

                    if (a.id > b.id) {
                        return 1
                    } else {
                        return -1
                    }
                });


                let elem = dato2.filter(d => d.id === 0)[0];

                $("#imgr2").attr("src", 'data:image/jpeg;base64,' + elem.imgR);
                $("#depthr2").attr("src", 'data:image/jpeg;base64,' + elem.depthR);

                $("#imgb2").attr("src", 'data:image/jpeg;base64,' + elem.imgB);
                $("#depthb2").attr("src", 'data:image/jpeg;base64,' + elem.depthB);


                drawPoints(dato2, proj2);
                drawElements(dato2, loc2);


                elements3 = proj2.selectAll(".projDot");
                elements4 = loc2.selectAll(".locDot");

            });


            // getData2("datasets/traj" + curTraj + "/" + curTraj + "_" + curNoise + ".json").then(function () {
            getData2("datasets/good/try2" + "_" + curNoise2 + ".json").then(function () {

                $("#timeline3").attr("max", dato3.length)
                dato3.sort((a, b) => {

                    if (a.id > b.id) {
                        return 1
                    } else {
                        return -1
                    }
                });


                let elem = dato3.filter(d => d.id === 0)[0];

                $("#imgr3").attr("src", 'data:image/jpeg;base64,' + elem.imgR)
                $("#depthr3").attr("src", 'data:image/jpeg;base64,' + elem.depthR)

                $("#imgb3").attr("src", 'data:image/jpeg;base64,' + elem.imgB)
                $("#depthb3").attr("src", 'data:image/jpeg;base64,' + elem.depthB)


                drawPoints(dato3, proj3);
                drawElements(dato3, loc3);

                elements5 = proj3.selectAll(".projDot");
                elements6 = loc3.selectAll(".locDot");


            });


            // debugInit();


            function debugInit() {
                loadmap(loc, 'assets/images/map.jpg');
                drawPoints(data, proj);
                drawElements(data, d3.select("#loc"));
            }

            async function getDatatry(url) {
                dat = await d3.json(url).then(d => {
                    return JSON.parse(d.replace(/'/g, '"'))
                });
            }


            async function getData0(url) {
                dato = await d3.json(url).then(d => {
                    return JSON.parse(d.replace(/'/g, '"'))
                });
            }

            async function getData1(url) {
                dato2 = await d3.json(url).then(d => {
                    return JSON.parse(d.replace(/'/g, '"'))
                });
            }

            async function getData2(url) {
                dato3 = await d3.json(url).then(d => {
                    return JSON.parse(d.replace(/'/g, '"'))
                });
            }


            async function getRef(url) {
                tref = await d3.json(url).then(d => {
                    return JSON.parse(d.replace(/'/g, '"'))
                });
            }


            async function getUmap(url) {
                dator = await d3.json(url).then(d => {
                    return JSON.parse(d.replace(/'/g, '"'))
                });
            }


            getUmap("umapout.json").then(function () {
                    var color = d3.scaleOrdinal(d3.schemeCategory10);

                    // p1 = [d3.extent(dator["umap"].map(d => d[0])), d3.extent(dator["umap"].map(d => d[1]))];


                    console.log([d3.extent(dator["umap"].map(d => d[0])), d3.extent(dator["umap"].map(d => d[1]))]);

                    console.log(p1);

                    let tbo = d3.select("#allProj")

                    let dxscale = d3.scaleLinear().domain(p1[0]).range([20, 515]); // Scale to Change based on SVG Size
                    let dyscale = d3.scaleLinear().domain(p1[1]).range([20, 515]);

                    let rooms = ["Uncertain", "RoomTheo", "RoomMate", "LivingRoom", "Laundry", "Kitchen", "Corridor", "Bathroom", "Hall"]

                    console.log(dator["umap"].length);

                    for (let i = 0; i < dator["umap"].length; i++) {

                        tbo.append("circle")
                            .attr("cx", dxscale(dator["umap"][i][0]))
                            .attr("cy", dyscale(dator["umap"][i][1]))
                            .attr("r", 2)
                            .attr('fill', color(dator["rooms"][i]))
                    }

                    for (let i = 0; i < 9; i++) {

                        tbo.append("circle")
                            .attr("cx", 500)
                            .attr("cy", 345 + (20 * i))
                            .attr("r", 5)
                            .attr("fill", color(i));

                        tbo.append("text")
                            .attr("text-anchor", "end")
                            .attr("x", 487)
                            .attr("y", 350 + (20 * i))
                            .text(rooms[i])

                    }

                }
            )


            /* getUmap("umapout.json").then(function () {

                 var color = d3.scaleOrdinal(d3.schemeCategory10);

                 let p1 = [d3.extent(dator["umap"].map(d => d[0])), d3.extent(dator["umap"].map(d => d[1]))];

                 let tbo2 = d3.select("#allProj2")

                 let dxscale2 = d3.scaleLinear().domain(p1[0]).range([20, 515]); // Scale to Change based on SVG Size
                 let dyscale2 = d3.scaleLinear().domain(p1[1]).range([20, 515]);


                 let rooms = ["Uncertain", "RoomTheo", "RoomMate", "LivingRoom", "Laundry", "Kitchen", "Corridor", "Bathroom", "Hall"]

                 console.log(dator);

                 for (let i = 0; i < dator["umap"].length; i++) {

                     tbo2.append("circle")
                         .attr("cx", dxscale2(dator["umap"][i][0]))
                         .attr("cy", dyscale2(dator["umap"][i][1]))
                         .attr("r", 2)
                         .attr('fill', color(dator["rooms"][i]))
                 }


                 for (let i = 0; i < 9; i++) {

                     tbo2.append("circle")
                         .attr("cx", 510)
                         .attr("cy", (510) - (20 * i))
                         .attr("r", 5)
                         .attr("fill", color(i));

                     tbo2.append("text")
                         .attr("text-anchor", "end")
                         .attr("x", 500)
                         .attr("y", (515) - (20 * i))
                         .text(rooms[i])
                 }
             });
         */

            function loadmap(svg, map) {

                svg.append('image')
                    .attr('xlink:href', map)
                    .attr('x', -40)
                    .attr('y', -15)
                    .style('width', '110%').moveToBack()
            }

            function handleCirHovSyncLoc(cirhov, coords, elements, elements2, loc, proj) {

                cirhov.transition().duration(25).attr("transform", "translate(" + coords[0] + ", " + coords[1] + ")")
                if (elements2) {
                    let inside = elements2.filter(d => {
                        return euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], coords) < 25
                    });

                    inside.transition().duration(5).attr("fill", "purple");
                    elements2.filter(d => {
                        return euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], coords) > 24
                    }).transition().duration(5).attr("fill", (d) => colscale(euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], [loc_xscacle(d.lx2), loc_yscacle(d.ly2)])))

                }

                // console.log(inside);


                let inside2 = elements.filter(d => {
                    return euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], coords) < 25
                });

                // console.log(elements2);
                inside2.transition().duration(5).attr("fill", "purple");


                elements.filter(d => {
                    return euclidian_dist([loc_xscacle(d.px1), loc_yscacle(d.py1)], coords) > 24
                }).transition().duration(5).attr("fill", (d) => colscale(euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], [proj_xscacle(d.px2), proj_yscacle(d.py2)])))


                elements.each((d) => {

                    // console.log(d);
                    if (euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], coords) < 25) {

                        if (!idSel.includes(d.id)) {
                            const orr = 180 - (Math.atan2(proj_yscacle(d.py1) - proj_yscacle(d.py2), proj_xscacle(d.px1) - proj_xscacle(d.px2)) * (180 / Math.PI));
                            const orr2 = 180 - (Math.atan2(loc_yscacle(d.ly1) - loc_yscacle(d.ly2), loc_xscacle(d.lx1) - loc_xscacle(d.lx2)) * (180 / Math.PI));

                            proj.append("path")
                                .attr("class", "tbrm")
                                // .style("transform-origin", "50% 50%")
                                .attr("num", d.id)
                                .attr("fill", "steelblue")
                                .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                                .attr("transform", "rotate(" + (orr) + " " + (proj_xscacle(d.px2) - 2) + " " + (proj_yscacle(d.py2) - 2) + ") translate(" + (proj_xscacle(d.px2) - 16) + "," + (proj_yscacle(d.py2) - 16) + ")  scale(0.5) ")

                            loc.append("path")
                                .attr("class", "tbrm")
                                .attr("num", d.id)
                                .attr("fill", "steelblue")
                                .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                                .attr("transform", "rotate(" + (orr2) + " " + (loc_xscacle(d.lx2) - 2) + " " + (loc_yscacle(d.ly2) - 2) + ") translate(" + (loc_xscacle(d.lx2) - 16) + "," + (loc_yscacle(d.ly2) - 16) + ")  scale(0.5) ")
                            // .attr("transform", "rotate(180 64 62) translate(50 50) scale(0.5)")

                            idSel.push(d.id)

                            let tpath = proj.append("line")
                                .attr("class", "tbrm")
                                .attr("num", d.id)
                                .attr("x1", proj_xscacle(d.px1))
                                .attr("y1", proj_yscacle(d.py1))
                                .attr("x2", proj_xscacle(d.px2))
                                .attr("y2", proj_yscacle(d.py2))
                                .attr('stroke', 'steelblue')
                                .style('stroke-width', '3px')

                            let totalLength = tpath.node().getTotalLength();

                            tpath.attr("stroke-dasharray", totalLength + " " + totalLength)
                                .attr("stroke-dashoffset", totalLength)
                                .transition()
                                .duration(250)
                                .attr("stroke-dashoffset", 0);


                            let tpath2 = loc.append("line")
                                .attr("class", "tbrm")
                                .attr("num", d.id)
                                .attr("x1", loc_xscacle(d.lx1))
                                .attr("y1", loc_yscacle(d.ly1))
                                .attr("x2", loc_xscacle(d.lx2))
                                .attr("y2", loc_yscacle(d.ly2))
                                .attr('stroke', 'steelblue')
                                .style('stroke-width', '3px')

                            let totalLength2 = tpath2.node().getTotalLength();

                            tpath2.attr("stroke-dasharray", totalLength2 + " " + totalLength2)
                                .attr("stroke-dashoffset", totalLength2)
                                .transition()
                                .duration(250)
                                .attr("stroke-dashoffset", 0)

                        }
                    } else {
                        let tid = idSel.indexOf(d.id);
                        if (tid) {
                            idSel.splice(tid)
                            d3.selectAll('.tbrm[num="' + d.id + '"]').remove()

                        }

                    }
                })
            }


            function handleCirHovSyncProj(cirhov, coords, elements, elements2, loc, proj) {


                cirhov.transition().duration(25).attr("transform", "translate(" + coords[0] + ", " + coords[1] + ")")


                let inside = elements.filter(d => {
                    return euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], coords) < 25 && d.id < curStep
                });
                inside.transition().duration(5).attr("fill", "purple");

                let inside2 = elements2.filter(d => {
                    return euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], coords) < 25 && d.id < curStep
                });
                inside2.transition().duration(5).attr("fill", "purple");

                elements2.filter(d => {
                    return euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], coords) > 24 && d.id < curStep
                }).transition().duration(5).attr("fill", (d) => colscale(euclidian_dist([loc_xscacle(d.lx1), loc_yscacle(d.ly1)], [loc_xscacle(d.lx2), loc_yscacle(d.ly2)])))


                elements.filter(d => {
                    return euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], coords) > 24 && d.id < curStep
                }).transition().attr("fill", (d) => colscale(euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], [proj_xscacle(d.px2), proj_yscacle(d.py2)])))


                elements.each((d) => {

                    // console.log(d);
                    if (euclidian_dist([proj_xscacle(d.px1), proj_yscacle(d.py1)], coords) < 25 && d.id < curStep) {

                        if (!idSel.includes(d.id)) {
                            const orr = 180 - (Math.atan2(proj_yscacle(d.py1) - proj_yscacle(d.py2), proj_xscacle(d.px1) - proj_xscacle(d.px2)) * (180 / Math.PI));
                            const orr2 = 180 - (Math.atan2(loc_yscacle(d.ly1) - loc_yscacle(d.ly2), loc_xscacle(d.lx1) - loc_xscacle(d.lx2)) * (180 / Math.PI));

                            proj.append("path")
                                .attr("class", "tbrm")
                                // .style("transform-origin", "50% 50%")
                                .attr("num", d.id)
                                .attr("fill", "steelblue")
                                .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                                .attr("transform", "rotate(" + (orr) + " " + (proj_xscacle(d.px2) - 2) + " " + (proj_yscacle(d.py2) - 2) + ") translate(" + (proj_xscacle(d.px2) - 16) + "," + (proj_yscacle(d.py2) - 16) + ")  scale(0.5) ")

                            loc.append("path")
                                .attr("class", "tbrm")
                                .attr("num", d.id)
                                .attr("fill", "steelblue")
                                .attr("d", "m 20 20 a -6 6 7 0 1 14 0 l -7 23 l -7 -23")
                                .attr("transform", "rotate(" + (orr2) + " " + (loc_xscacle(d.lx2) - 2) + " " + (loc_yscacle(d.ly2) - 2) + ") translate(" + (loc_xscacle(d.lx2) - 16) + "," + (loc_yscacle(d.ly2) - 16) + ")  scale(0.5) ")
                            // .attr("transform", "rotate(180 64 62) translate(50 50) scale(0.5)")

                            idSel.push(d.id)

                            let tpath = proj.append("line")
                                .attr("class", "tbrm")
                                .attr("num", d.id)
                                .attr("x1", proj_xscacle(d.px1))
                                .attr("y1", proj_yscacle(d.py1))
                                .attr("x2", proj_xscacle(d.px2))
                                .attr("y2", proj_yscacle(d.py2))
                                .attr('stroke', 'steelblue')
                                .style('stroke-width', '3px');

                            let totalLength = tpath.node().getTotalLength();

                            tpath.attr("stroke-dasharray", totalLength + " " + totalLength)
                                .attr("stroke-dashoffset", totalLength)
                                .transition()
                                .duration(250)
                                .attr("stroke-dashoffset", 0);


                            let tpath2 = loc.append("line")
                                .attr("class", "tbrm")
                                .attr("num", d.id)
                                .attr("x1", loc_xscacle(d.lx1))
                                .attr("y1", loc_yscacle(d.ly1))
                                .attr("x2", loc_xscacle(d.lx2))
                                .attr("y2", loc_yscacle(d.ly2))
                                .attr('stroke', 'steelblue')
                                .style('stroke-width', '3px')

                            let totalLength2 = tpath2.node().getTotalLength();

                            tpath2.attr("stroke-dasharray", totalLength2 + " " + totalLength2)
                                .attr("stroke-dashoffset", totalLength2)
                                .transition()
                                .duration(250)
                                .attr("stroke-dashoffset", 0)

                        }
                    } else {
                        let tid = idSel.indexOf(d.id);
                        if (tid) {
                            idSel.splice(tid)
                            d3.selectAll('.tbrm[num="' + d.id + '"]').remove()
                        }
                    }
                })
            }


            loc2.on('mousemove', function () {
                const coords = d3.mouse(loc2.node());
                handleCirHovSyncLoc(cirhov4, coords, elements3, elements4, loc2, proj2);
            })


            proj2.on('mousemove', function () {
                const coords = d3.mouse(proj2.node());
                handleCirHovSyncProj(cirhov3, coords, elements3, elements4, loc2, proj2);
            })


            loc3.on('mousemove', function () {
                const coords = d3.mouse(loc3.node());
                handleCirHovSyncLoc(cirhov6, coords, elements5, elements6, loc3, proj3);
            })


            proj3.on('mousemove', function () {
                const coords = d3.mouse(proj3.node());
                handleCirHovSyncProj(cirhov5, coords, elements5, elements6, loc3, proj3);
            })


            loc.on('mousemove', function () {

                const coords = d3.mouse(loc.node());
                // console.log('Lalalaa');
                handleCirHovSyncLoc(cirhov2, coords, elements, elements2, loc, proj);

            });


        </script>


</body>
</html>
